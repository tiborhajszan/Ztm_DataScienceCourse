{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Dog Breed Recognition Project"
      ],
      "metadata": {
        "id": "in9S_YUyBC-t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Project Basics"
      ],
      "metadata": {
        "id": "4i_hCz4abADf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Problem"
      ],
      "metadata": {
        "id": "8oZfaZ_xBf0f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our goal is to identify dog breed from a photo of the dog.  \n",
        "The project is taken from [Kaggle Dog Breed Identification Competition](https://www.kaggle.com/c/dog-breed-identification/data).  \n",
        "The machine learning problem is **supervised learning > multiclass classification**.  \n",
        "Our task is to build a neural network image classifier using TensorFlow and TensorFlow Hub."
      ],
      "metadata": {
        "id": "bYcVYrJYCNKn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluation"
      ],
      "metadata": {
        "id": "fzDR79sXBi51"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The evaluation metric set for the competition is Multiclass Log Loss.  \n",
        "Our target matrix contains N Dogs x M Breeds, true breed = 1, rest = 0.  \n",
        "Our model predicts a probability matrix with the same dimensions.  \n",
        "Multiclass Log Loss measures the error of model predictions (the lower the better).  \n",
        "Muticlass Log Loss is applied in image classification, natural language processing, and recommendation systems."
      ],
      "metadata": {
        "id": "fDhitkMhGtRO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Source"
      ],
      "metadata": {
        "id": "5jAW9IvXBrec"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data is acquired from [Kaggle Dog Breed Identification Competition](https://www.kaggle.com/c/dog-breed-identification/data)."
      ],
      "metadata": {
        "id": "pxafFCqUDZg2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Features / Data Dictionary"
      ],
      "metadata": {
        "id": "3p5Qyin9BuSG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our model analyzes image files (unstructured data) > deep learning / transfer learning.  \n",
        "There are 120 unique dog breeds in the training set > multiclass classification with 120 classes.  \n",
        "There are 10 222 images in the training set.  \n",
        "There are 10 357 images in the test set."
      ],
      "metadata": {
        "id": "DnGXzu-CKCie"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Libraries"
      ],
      "metadata": {
        "id": "1-7sc5BnNrJe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### importing tensorflow\n",
        "import tensorflow\n",
        "print(tensorflow.__version__)\n",
        "\n",
        "### checking gpu availability\n",
        "print(tensorflow.config.list_physical_devices())\n",
        "\n",
        "### importing tensorflow hub\n",
        "import tensorflow_hub as tfhub\n",
        "print(tfhub.__version__)\n",
        "\n",
        "### importing sklearn tools\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "### other imports\n",
        "from typing import List, Any\n",
        "from pathlib import Path\n",
        "import numpy\n",
        "from pandas import read_csv, Series, DataFrame, concat, get_dummies\n",
        "from matplotlib import pyplot\n",
        "from IPython.display import Image"
      ],
      "metadata": {
        "id": "F8J6sQlQNuiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Acquisition"
      ],
      "metadata": {
        "id": "i0xxhYPvd8K6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Uploading Data"
      ],
      "metadata": {
        "id": "_0j1UpM7Nele"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anTh-vJKG55O"
      },
      "outputs": [],
      "source": [
        "### unzipping project data\n",
        "#!unzip \"drive/MyDrive/Colab Data/dog-recognition.zip\" -d \"drive/MyDrive/Colab Data/\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Importing Labels"
      ],
      "metadata": {
        "id": "7cEYIV4w3omE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### importing labels\n",
        "labels_df = read_csv(filepath_or_buffer=\"drive/MyDrive/Colab Data/Dog Recognition/labels.csv\")"
      ],
      "metadata": {
        "id": "u48Ajtis9-YI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exploring Labels"
      ],
      "metadata": {
        "id": "Vy3Qe-3cgm0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### exploring labels: head\n",
        "labels_df.head()"
      ],
      "metadata": {
        "id": "RmkelXF9Yz9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### exploring labels: info\n",
        "labels_df.info()"
      ],
      "metadata": {
        "id": "iJqTWZ9p4chr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### exploring labels: unique breeds\n",
        "unique_breeds = labels_df[\"breed\"].unique().tolist()\n",
        "len(unique_breeds)"
      ],
      "metadata": {
        "id": "5tKl0ZEPZSkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### exploring labels: images / breed\n",
        "labels_df[\"breed\"].value_counts()"
      ],
      "metadata": {
        "id": "G9jIqj_p69Xj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### exploring labels: mean of images/breed\n",
        "round(number=labels_df[\"breed\"].value_counts().mean(), ndigits=3)"
      ],
      "metadata": {
        "id": "_BJk_mIw8R5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Google recommends at least 10 images per class.  \n",
        "We have adequate data with ~85 images per class on average."
      ],
      "metadata": {
        "id": "oXyJNET9-Ojj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing Data"
      ],
      "metadata": {
        "id": "pCXN_n-xNbh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creating Image Filepaths"
      ],
      "metadata": {
        "id": "oqVWPEF_2eyt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### counting number of images in train folder\n",
        "image_list = [image for image in Path(\"drive/MyDrive/Colab Data/Dog Recognition/train\").iterdir()]\n",
        "len(image_list)"
      ],
      "metadata": {
        "id": "OmFT6NELYLyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### creating image filepaths from image ids\n",
        "labels_df[\"imagepath\"] = \"drive/MyDrive/Colab Data/Dog Recognition/train/\" + labels_df[\"id\"] + \".jpg\""
      ],
      "metadata": {
        "id": "ObAn-Q-vUNNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### exploring imagepaths: head\n",
        "labels_df.head()"
      ],
      "metadata": {
        "id": "1G_5ZkpGbbsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### exploring imagepaths: info\n",
        "labels_df.info()"
      ],
      "metadata": {
        "id": "dEQZQ0lartA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### exploring imagepaths: checking validity of random imagepath\n",
        "print(labels_df.loc[9000, \"breed\"])\n",
        "print()\n",
        "print(labels_df.loc[9000, \"imagepath\"])\n",
        "print()\n",
        "Image(filename=labels_df.loc[9000, \"imagepath\"])"
      ],
      "metadata": {
        "id": "oNwXN8AaSd1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Reducing and Splitting"
      ],
      "metadata": {
        "id": "Yiwac2F6pSZY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### dataframe inits\n",
        "train_df = DataFrame()\n",
        "valid_df = DataFrame()"
      ],
      "metadata": {
        "id": "CFvyl-ZfPc3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### creating train and valid datasets\n",
        "for breed in unique_breeds:\n",
        "  work_df = labels_df.loc[labels_df[\"breed\"] == breed].copy(deep=True)\n",
        "  work_df = work_df.sample(n=12, random_state=42, ignore_index=True)\n",
        "  train_df = concat(objs=[train_df, work_df.loc[:9]], ignore_index=True, copy=True)\n",
        "  valid_df = concat(objs=[valid_df, work_df.loc[10:]], ignore_index=True, copy=True)"
      ],
      "metadata": {
        "id": "SbEuS-H5rjFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### shuffling train dataset\n",
        "train_df = train_df.sample(n=train_df.index.size, random_state=42, ignore_index=True)"
      ],
      "metadata": {
        "id": "r1A871GaO-Rr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### verifying dimensions of train and valid datasets\n",
        "train_df.shape, valid_df.shape"
      ],
      "metadata": {
        "id": "89mvfHSw5TD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creating Tensors"
      ],
      "metadata": {
        "id": "wLoH-H1_nekD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All machine learning algorithms require data in numerical format.  \n",
        "So the first task is to turn images and labels into tensors.  \n",
        "A tensor is a numerical matrix with n-dimensions, like a numpy ndarray."
      ],
      "metadata": {
        "id": "oXbLq4rs2kLa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### function creating image tensor\n",
        "def imageTensor(pInput_df=DataFrame(), pImage_size=224):\n",
        "  \"\"\"\n",
        "  Creates an image tensor from image filepaths.\n",
        "  \"\"\"\n",
        "  tensor_list = list()\n",
        "  for index,row in pInput_df.iterrows():\n",
        "    print(index)\n",
        "    image_tensor = tensorflow.io.read_file(filename=row[\"imagepath\"])\n",
        "    image_tensor = tensorflow.image.decode_jpeg(contents=image_tensor, channels=3)\n",
        "    image_tensor = tensorflow.image.convert_image_dtype(image=image_tensor, dtype=tensorflow.float32)\n",
        "    image_tensor = tensorflow.image.resize(images=image_tensor, size=[pImage_size, pImage_size])\n",
        "    tensor_list.append(image_tensor)\n",
        "  return tensorflow.stack(values=tensor_list, axis=0)"
      ],
      "metadata": {
        "id": "076CXYAb4Cvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### creating train image tensors\n",
        "train_images = imageTensor(pInput_df=train_df, pImage_size=224)\n",
        "train_images.shape"
      ],
      "metadata": {
        "id": "uSFFEb0KrF0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### creating valid image tensors\n",
        "valid_images = imageTensor(pInput_df=valid_df, pImage_size=224)\n",
        "valid_images.shape"
      ],
      "metadata": {
        "id": "IjIsYnVFLK4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### function creating label tensor\n",
        "def labelTensor(pInput_df=DataFrame()):\n",
        "  \"\"\"\n",
        "  Creates a label tensor from breed names.\n",
        "  \"\"\"\n",
        "  tensor_list = list()\n",
        "  for index,row in pInput_df.iterrows():\n",
        "    print(index)\n",
        "    label_array = numpy.zeros(shape=120, dtype=\"int8\")\n",
        "    label_array[unique_breeds.index(row[\"breed\"])] = 1\n",
        "    tensor_list.append(tensorflow.constant(value=label_array))\n",
        "  return tensorflow.stack(values=tensor_list, axis=0)"
      ],
      "metadata": {
        "id": "kxQQM9B_n93F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### creating train label tensors\n",
        "train_labels = labelTensor(pInput_df=train_df)\n",
        "train_labels.shape"
      ],
      "metadata": {
        "id": "55BjpDknNNwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### creating valid label tensors\n",
        "valid_labels = labelTensor(pInput_df=valid_df)\n",
        "valid_labels.shape"
      ],
      "metadata": {
        "id": "-NDMShCkvLI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Batches"
      ],
      "metadata": {
        "id": "Zbg__wK5ucV0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPUs have limited amount of memory.  \n",
        "The entire training dataset may not fit into GPU memory.  \n",
        "To resolve this, we split our datasets into batches of ~32 tensors.  \n",
        "The neural network sees only one batch at a time."
      ],
      "metadata": {
        "id": "VXC0FXyJuuVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### function creating data batches\n",
        "def dataBatches(pInput_tensors=tuple(), pBatch_size=32):\n",
        "  \"\"\"\n",
        "  Creates data batches from input tensors.\n",
        "  \"\"\"\n",
        "  ### creating dataset\n",
        "  data_set = tensorflow.data.Dataset.from_tensor_slices(tensors=pInput_tensors)\n",
        "  ### creating and returning data batches\n",
        "  return data_set.batch(batch_size=pBatch_size)"
      ],
      "metadata": {
        "id": "cPvLDLC4efLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### creating train data batches\n",
        "train_batches = dataBatches(pInput_tensors=(train_images,train_labels), pBatch_size=32)\n",
        "train_batches.element_spec"
      ],
      "metadata": {
        "id": "iCUH7R1bRY21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### creating valid data batches\n",
        "valid_batches = dataBatches(pInput_tensors=(valid_images,valid_labels), pBatch_size=32)\n",
        "valid_batches.element_spec"
      ],
      "metadata": {
        "id": "wtUJtnERDVDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Visualizing Datasets"
      ],
      "metadata": {
        "id": "oHEv7LC_Uv7n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### function visualizing a data batch\n",
        "def visualizeBatch(pImages=numpy.array([]), pLabels=numpy.array([])):\n",
        "  \"\"\"\n",
        "  Displays images and labels from a data batch.\n",
        "  \"\"\"\n",
        "  pyplot.figure(figsize=(8,12))\n",
        "  for index,image,label in zip(range(1, 33), pImages, pLabels):\n",
        "    axis = pyplot.subplot(8, 4, index)\n",
        "    pyplot.imshow(X=image)\n",
        "    pyplot.title(label=unique_breeds[label.argmax()], fontsize=8)\n",
        "    pyplot.axis(\"off\")\n",
        "  return"
      ],
      "metadata": {
        "id": "WAW3kh5jVI2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### visualizing first batch of train bathes\n",
        "images,labels = next(train_batches.as_numpy_iterator())\n",
        "visualizeBatch(pImages=images, pLabels=labels)"
      ],
      "metadata": {
        "id": "uxyhy8LcVtYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### visualizing first batch of valid bathes\n",
        "images,labels = next(valid_batches.as_numpy_iterator())\n",
        "visualizeBatch(pImages=images, pLabels=labels)"
      ],
      "metadata": {
        "id": "b3M3Q2xxZN_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building a Model"
      ],
      "metadata": {
        "id": "lcOLS9ljfgUd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### setting base model features\n",
        "INPUT_SHAPE = [None, 224, 224, 3] # batch, height, width, colorchannel\n",
        "OUTPUT_SHAPE = len(unique_breeds) # number of classes (breeds)\n",
        "MODEL_URL = \"https://www.kaggle.com/models/google/mobilenet-v2/TensorFlow2/130-224-classification/2\""
      ],
      "metadata": {
        "id": "sOnyYIosftAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Reducing Data: Working Subset"
      ],
      "metadata": {
        "id": "hlGcPdCnKeol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### splitting data working / rest\n",
        "PERCENT_IMAGES = 0.1 #@param {type:\"slider\", min:0.1, max:1.0, step:0.1}\n",
        "rest_features, work_features, rest_targets, work_targets = train_test_split(\n",
        "    features_series,\n",
        "    targets_df,\n",
        "    test_size=PERCENT_IMAGES,\n",
        "    random_state=42)"
      ],
      "metadata": {
        "id": "LwpycO0VKrAI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}