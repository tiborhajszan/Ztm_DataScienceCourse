{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-Learn (sklearn) Course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span>\n",
    "0. sklearn workflow overview<br>\n",
    "1. preparing data (collecting, exploring, cleaning, transforming, reducing, splitting)<br>\n",
    "2. defining problem / selecting machine learning model<br>\n",
    "3. training model and making predictions<br>\n",
    "<span style=\"color:orange\">4. evaluating model</span><br>\n",
    "5. improving model<br>\n",
    "6. saving and loading model<br>\n",
    "7. putting it all together\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluating Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- resources  \n",
    "[sklearn documentation > model evaluation](https://scikit-learn.org/stable/modules/model_evaluation.html)  \n",
    "[statquest youtube video: ROC and AUC explained](https://www.youtube.com/watch?v=4jRBRDbJemM)  \n",
    "[sklearn documentation > ROC curve for multiclass classification models](https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html)  \n",
    "<span style=\"color:red\">>>> Load and prepare data<span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- sklearn built-in evaluation methods  \n",
    "`model.score()` method  \n",
    "cross valiadion with `scoring=` parameter  \n",
    "metric functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- default `model.score()` and cross validation metrics  \n",
    "classification models: mean accuracy (true predictions / all predictions)  \n",
    "regression models: r^2 - [coefficient of determination](https://en.wikipedia.org/wiki/Coefficient_of_determination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- cross validation  \n",
    "creates `cv=k` different train/test splits from the same dataset (k-fold cross validation)  \n",
    "trains and scores the algorithm on all splits > training covers the entire dataset  \n",
    "scoring metric is defined by the `scoring=` parameter (`scoring=None` invokes the default scorer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- classification model metrics  \n",
    "**mean accuracy** true predictions / all predictions  \n",
    "**receiver operating characteristic (ROC) curve**  see below  \n",
    "**area under the ROC curve (AUC)** see below  \n",
    "**confusion matrix**  see below  \n",
    "classification report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- receiver operating characteristic (ROC) curve  \n",
    "plots true positive rate (tpr) over false positive rate (fpr)  \n",
    "tpr = specificity = recall: true positive predictions / all positive targets  \n",
    "fpr (1 - sensitivity): false positive predictions / all negative targets  \n",
    "suitable for binary classification models  \n",
    "visualizes the effect of varying the algorithm decision threshold  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- ROC curve for multiclass classification models  \n",
    "a ROC curve works with binary output, so multiclass output must be binarized  \n",
    "one-vs-rest: comparing each class to all the others  \n",
    "one-vs-one: comparing every pairwise combination of classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- area under the ROC curve (AUC)  \n",
    "integral of ROC curve > ranges between 0.0-1.0  \n",
    "used to compare the performance of different algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- confusion matrix  \n",
    "a quick way to compare predictions to targets  \n",
    "gives an idea of where the model is confused"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- coding tricks within jupyter notebook  \n",
    "**`!command`, e.g., `!dir`** runs terminal command within jupyter notebook  \n",
    "**`sklearn.__version__`** displays version of installed module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### imports ------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "import numpy, pandas\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### preparing data -----------------------------------------------------------------------------------------------------\n",
    "\n",
    "### loading heart disease classification data into dataframe\n",
    "heart_disease = pandas.read_csv(\"data-heart-disease.csv\")\n",
    "\n",
    "### splitting data features/target\n",
    "features = heart_disease.drop(columns=\"target\")\n",
    "target = heart_disease.loc[:, \"target\"]\n",
    "\n",
    "### splitting data train/test\n",
    "numpy.random.seed(42)\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### creating random forest classifier ----------------------------------------------------------------------------------\n",
    "\n",
    "### instantiating model\n",
    "numpy.random.seed(42)\n",
    "classifier = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "### training model\n",
    "classifier.fit(features_train, target_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: Update kwargs!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### imports ------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### evaluating model with model.score() method on training data --------------------------------------------------------\n",
    "classifier.score(X=features_train, y=target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### evaluating model with model.score() method on test data ------------------------------------------------------------\n",
    "classifier.score(X=features_test, y=target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### evaluating model with default score (accuracy) cross validation ----------------------------------------------------\n",
    "cv_list = cross_val_score(estimator=classifier, X=features, y=target, cv=5, scoring=None)\n",
    "cv_mean = numpy.mean(cv_list)0\n",
    "cv_list, cv_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### function for plotting ROC curve ------------------------------------------------------------------------------------\n",
    "\n",
    "### function init\n",
    "def plotRoc(fpr, tpr):\n",
    "    \"\"\"\n",
    "    Plots ROC curve, i.e., true positive rate (tpr) over false positive rate (fpr)\n",
    "    \"\"\"\n",
    "\n",
    "    ### plotting ROC curve\n",
    "    pyplot.plot(fpr, tpr, color=\"orange\", label=\"ROC curve\")\n",
    "\n",
    "    ### plotting baseline\n",
    "    pyplot.plot([0,1], [0,1], color=\"blue\", linestyle=\"--\", label=\"Guessing\")\n",
    "\n",
    "    ### customizing plot\n",
    "    pyplot.title(\"Receiver Operating Characteristic (ROC) Curve\")\n",
    "    pyplot.ylabel(\"True Positive Rate\")\n",
    "    pyplot.xlabel(\"False Positive Rate\")\n",
    "    pyplot.legend()\n",
    "\n",
    "    ### rendering plot\n",
    "    pyplot.show()\n",
    "\n",
    "    ### function termination\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### evaluating model with ROC curve ------------------------------------------------------------------------------------\n",
    "predict_positive_probs = classifier.predict_proba(features_test)[:, 1]\n",
    "model_fpr, model_tpr, model_thresholds = roc_curve(target_test, predict_positive_probs)\n",
    "perfect_fpr, perfect_tpr, perfect_threshold = roc_curve(target_test, target_test)\n",
    "plotRoc(model_fpr, model_tpr), plotRoc(perfect_fpr, perfect_tpr);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### evaluating model with AUC score ------------------------------------------------------------------------------------\n",
    "model_auc = roc_auc_score(target_test, predict_positive_probs)\n",
    "perfect_auc = roc_auc_score(target_test, target_test)\n",
    "model_auc, perfect_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### evaluating model with confusion matrix -----------------------------------------------------------------------------\n",
    "target_preds = classifier.predict(features_test)\n",
    "pandas.crosstab(target_test, target_preds, rownames=[\"Targets\"], colnames=[\"Predictions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### visualizing confusion matrix with sklearn --------------------------------------------------------------------------\n",
    "ConfusionMatrixDisplay.from_predictions(y_true=target_test, y_pred=target_preds);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### imports ------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### preparing data -----------------------------------------------------------------------------------------------------\n",
    "\n",
    "### loading california housing dataset\n",
    "housing_dict = fetch_california_housing()\n",
    "\n",
    "### creating california housing dataframe\n",
    "housing_df = pandas.DataFrame(data=housing_dict[\"data\"], columns=housing_dict[\"feature_names\"])\n",
    "housing_df[\"MedHouseVal\"] = housing_dict[\"target\"]\n",
    "\n",
    "### splitting data features/target\n",
    "features = housing_df.drop(columns=\"MedHouseVal\")\n",
    "target = housing_df.loc[:, \"MedHouseVal\"]\n",
    "\n",
    "### splitting data train/test\n",
    "numpy.random.seed(42)\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### creating random forest regressor -----------------------------------------------------------------------------------\n",
    "\n",
    "### instantiating model\n",
    "numpy.random.seed(42)\n",
    "regressor = RandomForestRegressor(n_estimators=100)\n",
    "\n",
    "### training model\n",
    "regressor.fit(features_train, target_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### evaluating model with .score() method ------------------------------------------------------------------------------\n",
    "regressor.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### predicting with predict() function ---------------------------------------------------------------------------------\n",
    "target_prediction = regressor.predict(features_test)\n",
    "target_prediction[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### comparing predictions to true values / metrics.mean_absolute_error function ----------------------------------------\n",
    "mean_absolute_error(target_test, target_prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('Ztm_Code': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d135630f3aba14e844087208813e69ab65195afd4ab5238b4ebe56330592421"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
