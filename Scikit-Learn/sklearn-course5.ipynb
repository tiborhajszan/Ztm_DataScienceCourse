{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-Learn (Sklearn) Course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span>\n",
    "0. sklearn workflow overview<br>\n",
    "1. preparing data (exploring, cleaning, transforming, reducing, splitting)<br>\n",
    "2. selecting machine learning model / algorithm<br>\n",
    "3. training algorithm and making predictions<br>\n",
    "4. evaluating algorithm<br>\n",
    "<span style=\"color:orange\">5. improving model</span><br>\n",
    "6. saving and loading algorithm<br>\n",
    "7. putting it all together\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Improving the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- baseline  \n",
    "first model = baseline model  \n",
    "first prediction = baseline prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- improving model / data perspective  \n",
    "collecting more data (the more data the better)  \n",
    "improving data > adding more features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- improving model / algorithm perspective  \n",
    "using a better, more complex algorithm  \n",
    "improving current algorithm with hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- hyperparameters  \n",
    "settings of the algorithm that the user can adjust  \n",
    "basically, hyperparameters are the function parameters of the algorithm instance  \n",
    "hyperparameters are detailed in the documentation of each algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- hyperparameter adjustment methods  \n",
    "by hand (guessing)  \n",
    "random search with RandomSearchCV() algorithm  \n",
    "exhaustive search (brute force) with GridSeachCV() algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### imports\n",
    "import numpy, pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### preparing data\n",
    "\n",
    "### loading heart disease data into dataframe\n",
    "heart_disease = pandas.read_csv(\"data-heart-disease.csv\")\n",
    "\n",
    "### shuffling heart disease dataframe\n",
    "numpy.random.seed(42)\n",
    "heart_disease = heart_disease.sample(frac=1.0)\n",
    "\n",
    "### splitting data features <> target\n",
    "features = heart_disease.drop(columns=\"target\")\n",
    "target = heart_disease.loc[:, \"target\"]\n",
    "\n",
    "### splitting data train <> test\n",
    "train_index = round(0.7 * heart_disease.index.size)\n",
    "valid_index = round(0.85 * heart_disease.index.size)\n",
    "features_train, target_train = features[:train_index], target[:train_index]\n",
    "features_valid, target_valid = features[train_index:valid_index], target[train_index:valid_index]\n",
    "features_test, target_test = features[valid_index:], target[valid_index:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning hyperparameters by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### imports\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### classification algorithm evaluation function\n",
    "def evaluatePreds(target_preds, target_valid):\n",
    "    metric_dict = {\n",
    "        \"accuracy\": accuracy_score(y_pred=target_preds, y_true=target_valid),\n",
    "        \"precision\": precision_score(y_pred=target_preds, y_true=target_valid),\n",
    "        \"recall\": recall_score(y_pred=target_preds, y_true=target_valid),\n",
    "        \"f1\": f1_score(y_pred=target_preds, y_true=target_valid)}\n",
    "    print(f\"\"\"Accuracy: {100.0 * metric_dict[\"accuracy\"]:.3f}%\"\"\")\n",
    "    print(f\"\"\"Precision: {100.0 * metric_dict[\"precision\"]:.3f}%\"\"\")\n",
    "    print(f\"\"\"Recall: {100.0 * metric_dict[\"recall\"]:.3f}%\"\"\")\n",
    "    print(f\"\"\"F1 Score: {100.0 * metric_dict[\"f1\"]:.3f}%\"\"\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### creating and evaluating baseline algorithm\n",
    "\n",
    "### creating, training, predicting algorithm\n",
    "numpy.random.seed(42)\n",
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(X=features_train, y=target_train)\n",
    "target_preds = classifier.predict(X=features_valid)\n",
    "\n",
    "### evaluating algorithm\n",
    "evaluatePreds(target_preds, target_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### reading default hyperparameters of baseline algorithm\n",
    "classifier.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- hyperparameters to adjust  \n",
    "`max_depth=`  \n",
    "`max_features=`  \n",
    "`min_samples_leaf=`  \n",
    "`min_samples_split=`  \n",
    "`n_estimators=`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### creating and evaluating adjusted algorithm (max_depth=10)\n",
    "\n",
    "### creating, training, predicting algorithm\n",
    "numpy.random.seed(42)\n",
    "classifier = RandomForestClassifier(max_depth=10)\n",
    "classifier.fit(X=features_train, y=target_train)\n",
    "target_preds = classifier.predict(X=features_valid)\n",
    "\n",
    "### evaluating algorithm\n",
    "evaluatePreds(target_preds, target_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### creating and evaluating adjusted algorithm (n_estimators=500)\n",
    "\n",
    "### creating, training, predicting algorithm\n",
    "numpy.random.seed(42)\n",
    "classifier = RandomForestClassifier(n_estimators=500)\n",
    "classifier.fit(X=features_train, y=target_train)\n",
    "target_preds = classifier.predict(X=features_valid)\n",
    "\n",
    "### evaluating algorithm\n",
    "evaluatePreds(target_preds, target_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning hyperparameters with randomized search cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### imports\n",
    "import numpy, pandas\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### preparing data\n",
    "\n",
    "### loading heart disease data into dataframe\n",
    "heart_disease = pandas.read_csv(\"data-heart-disease.csv\")\n",
    "\n",
    "### splitting data features <> target\n",
    "features = heart_disease.drop(columns=\"target\")\n",
    "target = heart_disease.loc[:, \"target\"]\n",
    "\n",
    "### splitting data train <> test\n",
    "numpy.random.seed(42)\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### running randomized search\n",
    "\n",
    "### creating search grid\n",
    "search_grid = {\n",
    "    \"max_depth\": [None, 5, 10, 20, 30],\n",
    "    \"max_features\": [\"sqrt\"],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"min_samples_split\": [2, 4, 6],\n",
    "    \"n_estimators\": [10, 100, 200, 500, 1000, 1200]}\n",
    "\n",
    "### creating randomized search algorithm\n",
    "numpy.random.seed(42)\n",
    "rscv_classifier = RandomizedSearchCV(\n",
    "    estimator=RandomForestClassifier(n_jobs=-1),\n",
    "    param_distributions=search_grid,\n",
    "    n_iter=10, cv=5, verbose=2)\n",
    "\n",
    "### training randomized search algorithm\n",
    "rscv_classifier.fit(X=features, y=target);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### reading best parameters\n",
    "rscv_classifier.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### evaluating algorithm\n",
    "target_preds = rscv_classifier.predict(features_test)\n",
    "evaluatePreds(target_preds, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### imports\n",
    "import numpy, pandas\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### preparing data\n",
    "\n",
    "### loading california housing dataset\n",
    "housing_dict = fetch_california_housing()\n",
    "\n",
    "### creating california housing dataframe\n",
    "housing_df = pandas.DataFrame(data=housing_dict[\"data\"], columns=housing_dict[\"feature_names\"])\n",
    "housing_df[\"MedHouseVal\"] = housing_dict[\"target\"]\n",
    "\n",
    "### splitting data features/target\n",
    "features = housing_df.drop(columns=\"MedHouseVal\")\n",
    "target = housing_df.loc[:, \"MedHouseVal\"]\n",
    "\n",
    "### splitting data train/test\n",
    "numpy.random.seed(42)\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.2)\n",
    "target_test: numpy.ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### random forest regressor training and prediction\n",
    "\n",
    "### instantiating model\n",
    "numpy.random.seed(42)\n",
    "regressor = RandomForestRegressor(n_estimators=100)\n",
    "\n",
    "### training model / prediction\n",
    "regressor.fit(X=features_train, y=target_train)\n",
    "target_preds = regressor.predict(X=features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### imports\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- `.score()` method  \n",
    "default `.score()` and cross validation metric for regression models is [coefficient of determination (r^2)](https://en.wikipedia.org/wiki/Coefficient_of_determination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### evaluating algorithm with .score() method on test data\n",
    "regressor.score(X=features_test, y=target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- coefficient of determination (r2-score)  \n",
    "when a model predicts the mean of targets, its r2-score is 0.0  \n",
    "when a model perfectly predicts all targets, its r2-score is 1.0  \n",
    "`numpy.full(shape=, fill_value=)` creates an array of `shape=` filled with `fill_value=`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### getting r2-score of 0.0\n",
    "target_test_mean = numpy.full(shape=len(target_test), fill_value=target_test.mean())\n",
    "r2_score(y_true=target_test, y_pred=target_test_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### getting r2-score of 1.0\n",
    "r2_score(y_true=target_test, y_pred=target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### evaluating algorithm with cross-validated default score (r2-score)\n",
    "numpy.random.seed(42)\n",
    "cv_r2 = cross_val_score(estimator=regressor, X=features, y=target, cv=3, scoring=None)\n",
    "cv_r2.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- mean absolute error (MAE)  \n",
    "mean of absolute differences between predictions and targets  \n",
    "represents the linear magnitude of prediction error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### computing mean absolute error with sklearn function\n",
    "mean_absolute_error(y_true=target_test, y_pred=target_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### computing mean absolute error step-by-step\n",
    "error_df = pandas.DataFrame(data={\"target preds\": target_preds, \"target test\": target_test})\n",
    "error_df[\"differences\"] = numpy.abs(error_df[\"target preds\"] - error_df[\"target test\"])\n",
    "error_df[\"differences\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### evaluating algorithm with cross-validated mean absolute error\n",
    "numpy.random.seed(42)\n",
    "cv_mae = cross_val_score(estimator=regressor, X=features, y=target, cv=3, scoring=\"neg_mean_absolute_error\")\n",
    "cv_mae.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- mean squared error (MSE)  \n",
    "mean of squared differences between predictions and targets  \n",
    "squaring emphasizes large errors and diminishes small errors  \n",
    "there is also root mean squared error (RMSE) - see sklearn documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### computing mean squared error with sklearn function\n",
    "mean_squared_error(y_true=target_test, y_pred=target_preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('Ztm_Code': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d135630f3aba14e844087208813e69ab65195afd4ab5238b4ebe56330592421"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
