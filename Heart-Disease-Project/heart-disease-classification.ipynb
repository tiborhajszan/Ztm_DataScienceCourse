{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Heart Disease Using Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We attempt to create a machine learning model that detects heart disease based on the medical records of patients.  \n",
    "This notebook uses various Python libraries for data science and machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Problem definition  \n",
    "2. Data  \n",
    "3. Evaluation  \n",
    "4. Features  \n",
    "5. Modeling  \n",
    "6. Experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given certain medical records of a patient, is it possible to detect whether the patient suffers from heart disease?  \n",
    "The machine learning problem is **supervised learning / binary classification**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we use is the Cleveland Heart Disease Dataset, which is publicly available:  \n",
    "[UCI Machine Learning Repository](https://archive.ics.uci.edu/dataset/45/heart+disease)  \n",
    "[Kaggle](https://www.kaggle.com/datasets/redwankarimsony/heart-disease-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are trying to achieve 95% accuracy with the proof of concept model to pursue the project further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Dictionary (information about each data feature)**  \n",
    "* age (age of patient in years)  \n",
    "* sex (0=female, 1=male)  \n",
    "* cp (chest pain type: 1=typical angina, 2=atypical angina, 3=non-anginal, 4=asymptomatic)  \n",
    "* trestbps (resting blood pressure in mmHg on admission to hospital)  \n",
    "* chol (serum cholesterol in mg/dl)  \n",
    "* fbs (whether fasting blood sugar is > 120 mg/dl: 0=no, 1=yes)  \n",
    "* restecg (resting electrocardiographic results: 0=normal, 1=ST/T abnormality, 2=left ventricular hypertrophy)  \n",
    "* thalach (maximum heart rate achieved)  \n",
    "* exang (exercise-induced angina: 0=no, 1=yes)  \n",
    "* oldpeak (ST segment depression induced by exercise relative to resting)  \n",
    "* slope (slope of the peak exercise ST segment: 1=upsloping, 2=flat, 3=downsloping)  \n",
    "* ca (number of major vessels [0-3] colored by fluoroscopy)  \n",
    "* thal (1-3=normal, 6=fixed defect, 7=reversible defect)  \n",
    "* target (the predicted attribute: 0=no heart disease, 1=heart disease)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python libraries Numpy, Pandas, and Matplotlib are used for data analysis and manipulation.  \n",
    "Python library Scikit-Learn (SkLearn) is used for machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### importing exploratory data analysis (EDA) tools\n",
    "import numpy, pandas, seaborn\n",
    "from matplotlib import pyplot\n",
    "\n",
    "### rendering plots inside this notebook\n",
    "%matplotlib inline\n",
    "\n",
    "### importing sklearn model selection tools\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "### importing sklearn machine learning algorithms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "### importing sklearn model evaluation tools\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import RocCurveDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### importing from csv file\n",
    "heart_disease = pandas.read_csv(filepath_or_buffer=\"data-heart-disease.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### displaying dimensins of the dataframe\n",
    "heart_disease.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### displaying the first 5 rows\n",
    "heart_disease.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### displaying the last 5 rows\n",
    "heart_disease.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis = EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to become a subject matter expert on the dataset.  \n",
    "1. Data basics: data types, numeric/categorical, statistics, balanced/imbalanced, etc...\n",
    "2. Cleaning data: handling missing values and outliers\n",
    "3. Transforming data: common units, standardization, encoding, etc...\n",
    "4. Data engineering: creating new features from existing ones\n",
    "5. Reducing data: removing non-relevant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### displaying dataframe basic information\n",
    "heart_disease.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### displaying basic statistics\n",
    "heart_disease.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### counting category instances of the target variable\n",
    "heart_disease[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### visualizing category instances of the target variable\n",
    "heart_disease[\"target\"].value_counts().plot(kind=\"bar\", color=[\"salmon\", \"lightblue\"])\n",
    "pyplot.title(label=\"Category Instances of Target Variable\")\n",
    "pyplot.ylabel(ylabel=\"Counts\")\n",
    "pyplot.xlabel(xlabel=\"Target Variable (Heart Disease): 0=No 1=Yes\")\n",
    "pyplot.xticks(rotation=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### checking for missing values\n",
    "heart_disease.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sex of patient and heart disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### counting category instances of sex variable :)\n",
    "### sex: 0=female, 1=male\n",
    "heart_disease[\"sex\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### comparing sex column to target column with cross tabulation\n",
    "### sex: 0=female, 1=male\n",
    "### target: 0=no disease, 1=disease\n",
    "pandas.crosstab(index=heart_disease[\"sex\"], columns=heart_disease[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plotting heart disease frequency over sex of patient\n",
    "pandas.crosstab(index=heart_disease[\"sex\"], columns=heart_disease[\"target\"]).plot(\n",
    "    kind=\"bar\", color=[\"lightblue\", \"salmon\"])\n",
    "pyplot.title(label=\"Heart Disease Frequency by Sex\")\n",
    "pyplot.ylabel(ylabel=\"Patient Count\")\n",
    "pyplot.xlabel(xlabel=\"Sex of Patient\")\n",
    "pyplot.legend([\"No Heart Disease\", \"Heart Disease\"])\n",
    "pyplot.xticks(ticks=[0,1], labels=[\"Female\", \"Male\"], rotation=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maximum Heart Rate vs. Age and Heart Disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### histogram: distribution of maximum heart rate values\n",
    "heart_disease[\"thalach\"].plot.hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### histogram: distribution of age values\n",
    "heart_disease[\"age\"].plot.hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### creating figure object\n",
    "pyplot.figure(figsize=(10,6))\n",
    "\n",
    "### scatter plot: maximum heart rate over age in no heart disease\n",
    "pyplot.scatter(\n",
    "    y=heart_disease[\"thalach\"][heart_disease[\"target\"]==0],\n",
    "    x=heart_disease[\"age\"][heart_disease[\"target\"]==0],\n",
    "    color=\"lightblue\")\n",
    "\n",
    "### scatter plot: maximum heart rate over age in heart disease\n",
    "pyplot.scatter(\n",
    "    y=heart_disease[\"thalach\"][heart_disease[\"target\"]==1],\n",
    "    x=heart_disease[\"age\"][heart_disease[\"target\"]==1],\n",
    "    color=\"salmon\")\n",
    "\n",
    "### configuring scatter plots\n",
    "pyplot.title(label=\"Maximum Heart Rate vs. Age and Heart Disease\")\n",
    "pyplot.legend([\"No Heart Disease\", \"Heart Disease\"]);\n",
    "pyplot.ylabel(ylabel=\"Maximum Heart Rate\")\n",
    "pyplot.xlabel(xlabel=\"Age of Patient\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chest pain type and heart disease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*cp (chest pain type)*\n",
    "* 1 = typical angina (chest pain related to impaired blood supply of heart)\n",
    "* 2 = atypical angina (chest pain not related to impaired blood supply of heart)\n",
    "* 3 = non-anginal (typically easophageal spasm)\n",
    "* 4 = asymptomatic (chest pain not related to heart disease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### crosstab: chest pain type vs heart disease\n",
    "pandas.crosstab(index=heart_disease[\"cp\"], columns=heart_disease[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### bar graph: heart disease frequency over chest pain type\n",
    "pandas.crosstab(index=heart_disease[\"cp\"], columns=heart_disease[\"target\"]).plot(\n",
    "    kind=\"bar\", color=[\"lightblue\", \"salmon\"])\n",
    "\n",
    "### configuring bar graph\n",
    "pyplot.title(label=\"Heart Disease Frequency Over Chest Pain Type\")\n",
    "pyplot.legend([\"No Heart Disease\", \"Heart Disease\"])\n",
    "pyplot.ylabel(ylabel=\"Patient Count\")\n",
    "pyplot.xlabel(xlabel=\"Chest Pain Type\")\n",
    "pyplot.xticks(ticks=[0,1,2,3], labels=[\"Typical Angina\", \"Atypical Angina\", \"Non-Anginal\", \"Asymptomatic\"], rotation=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### creating correlation matrix with pandas\n",
    "correlation_matrix = heart_disease.corr()\n",
    "correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### visualizing correlation matrix with seaborn\n",
    "figure, axis = pyplot.subplots(figsize=(14,10))\n",
    "axis = seaborn.heatmap(data=correlation_matrix, linewidths=1.0, cmap=\"YlGnBu\", annot=True, fmt=\".2f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting data into training and test sets.  \n",
    "The machine learning algorithm is trained (finds patterns) on the training set.  \n",
    "The trained algorithm is then tested (applies patterns) on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### splitting data features <> target\n",
    "features = heart_disease.drop(columns=\"target\")\n",
    "target = heart_disease.loc[:, \"target\"]\n",
    "\n",
    "### splitting data train <> test\n",
    "numpy.random.seed(seed=42)\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting machine learning algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Three machine learning algorithms will be applied and compared**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Logistic Regression\n",
    "2. K-Nearest Neighbours Classifier\n",
    "3. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These algorithms were selected from to the sklearn model selection map.  \n",
    "[Sklearn Model Selection Map](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### creating algorithm dictionary\n",
    "algo_dict = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"K-Nearest Neighbours Classifier\": KNeighborsClassifier(),\n",
    "    \"Random Forest Classifier\": RandomForestClassifier()}\n",
    "\n",
    "### creating scores dictionary\n",
    "score_dict = {}\n",
    "\n",
    "### training and evaluating algorithms\n",
    "numpy.random.seed(seed=42)\n",
    "for name, algo in algo_dict.items():\n",
    "    algo.fit(features_train, target_train)\n",
    "    score_dict[name] = algo.score(features_test, target_test)\n",
    "\n",
    "### displaying scores\n",
    "score_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### visualizing algorithm performance\n",
    "score_df = pandas.DataFrame(data=score_dict, index=[\"Accuracy\"])\n",
    "score_df.T.plot(kind=\"bar\", figsize=(8,6), legend=None)\n",
    "pyplot.title(label=\"Algorithm Performance on the Heart Disease Dataset\", fontsize=14)\n",
    "pyplot.ylabel(ylabel=\"Accuracy\", fontsize=14)\n",
    "pyplot.xticks(rotation=0)\n",
    "pyplot.xlabel(xlabel=\"Machine Learning Algorithm\", fontsize=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model improvement / Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a baseline model that we try to improve using:\n",
    "* hyperparameter tuning\n",
    "* feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tools for evaluating the performance of a classification algorithm:\n",
    "* confusion matrix\n",
    "* classification report\n",
    "* accuracy / precision / recall / f1-score\n",
    "* cross-validation\n",
    "* ROC curve / area under the ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### nearest neighbors classifier hyperparameter tuning by hand\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "for k_neighbors in range(1,21):\n",
    "    knn_classifier.set_params(n_neighbors=k_neighbors)\n",
    "    knn_classifier.fit(X=features_train, y=target_train)\n",
    "    train_scores.append(knn_classifier.score(X=features_train, y=target_train))\n",
    "    test_scores.append(knn_classifier.score(X=features_test, y=target_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plotting nearest neighbors classifier tuning scores\n",
    "pyplot.plot(range(1,21), train_scores, label=\"Training Scores\")\n",
    "pyplot.plot(range(1,21), test_scores, label=\"Test Scores\")\n",
    "pyplot.title(label=\"Nearest Neighbors Classifier Hyperparameter Tuning\")\n",
    "pyplot.ylabel(ylabel=\"Accurarcy\")\n",
    "max_score = max(test_scores)\n",
    "pyplot.axhline(y=max_score, color=\"black\", linestyle=\"dotted\", label=f\"Best Score = {max_score:.3f}\")\n",
    "pyplot.xlabel(xlabel=\"Number of Neighbors\")\n",
    "pyplot.xticks(ticks=range(1,21,2))\n",
    "best_param = test_scores.index(max(test_scores)) + 1\n",
    "pyplot.axvline(x=best_param, color=\"black\", linestyle=\"dashed\", label=f\"Best Param = {best_param}\")\n",
    "pyplot.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning using Randomized Search Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance of the K Nearest Neighbors Classifier algorithm is too weak - no further use...  \n",
    "We continue by searching for better hyperparameters of Logistic Regression and Random Forest Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### logistic regression: creating hyperparameter grid\n",
    "logreg_grid = {\n",
    "    \"C\": numpy.logspace(start=-4, stop=4, num=20),\n",
    "    \"solver\": [\"liblinear\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### logistic regression: randomized search for best parameters\n",
    "numpy.random.seed(seed=42)\n",
    "logreg_random = RandomizedSearchCV(\n",
    "    estimator=LogisticRegression(), param_distributions=logreg_grid, cv=5, n_iter=20, verbose=True)\n",
    "logreg_random.fit(X=features, y=target)\n",
    "logreg_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### logistic regression: scoring best model\n",
    "logreg_random.score(X=features_test, y=target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### random forest classifier: creating hyperparameter grid\n",
    "forest_grid = {\n",
    "    \"n_estimators\": range(10, 1000, 50),\n",
    "    \"max_depth\": [None, 3, 5, 10],\n",
    "    \"min_samples_split\": range(2, 20, 2),\n",
    "    \"min_samples_leaf\": range(1, 20, 2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### random forest classifier: randomized search for best parameters\n",
    "numpy.random.seed(seed=42)\n",
    "forest_random = RandomizedSearchCV(\n",
    "    estimator=RandomForestClassifier(), param_distributions=forest_grid, cv=5, n_iter=20, verbose=True)\n",
    "forest_random.fit(X=features, y=target)\n",
    "forest_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### random forest classifier: scoring best model\n",
    "forest_random.score(X=features_test, y=target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning using Grid Search Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After randomized hyperparameter search, the Logistic Regression algorithm provides the best performance.  \n",
    "We continue by tuning the Logistic Regression algorithm even further (if possible).  \n",
    "We use Grid Search Cross Validation that performs an exhaustive hyperparameter search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### logistic regression: creating hyperparameter dictionary\n",
    "logreg_params = {\n",
    "    \"C\": numpy.logspace(start=-4, stop=4, num=30),\n",
    "    \"solver\": [\"liblinear\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### logistic regression: grid search for best parameters\n",
    "logreg_grid = GridSearchCV(estimator=LogisticRegression(), param_grid=logreg_params, cv=5, verbose=True)\n",
    "logreg_grid.fit(X=features, y=target)\n",
    "logreg_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### logistic regression: scoring best model\n",
    "logreg_grid.score(X=features_test, y=target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The following metrics will be computed:**\n",
    "* Confusion Matrix\n",
    "* Classification Report\n",
    "* Precision\n",
    "* Recall\n",
    "* F1 Score\n",
    "* ROC Curve and AUC Score\n",
    "\n",
    "Cross validation will be applied where possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### making predictions with best model\n",
    "target_preds = logreg_grid.predict(X=features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plotting roc curve of best model\n",
    "RocCurveDisplay.from_estimator(estimator=logreg_grid, X=features_test, y=target_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plotting confusion matrix using seaborn heatmap\n",
    "seaborn.set(font_scale=1.5)\n",
    "figure, axis = pyplot.subplots(figsize=(3,3))\n",
    "axis = seaborn.heatmap(data=confusion_matrix(y_true=target_test, y_pred=target_preds), annot=True, cbar=False)\n",
    "axis.set_ylabel(ylabel=\"Target Labels\")\n",
    "axis.xaxis.set_ticks_position(position=\"top\")\n",
    "axis.tick_params(axis=\"x\", which=\"both\", top=False)\n",
    "axis.xaxis.set_label_position(position=\"top\")\n",
    "axis.set_xlabel(xlabel=\"Predicted Labels\", labelpad=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### obtaining classification report\n",
    "print(classification_report(y_true=target_test, y_pred=target_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
