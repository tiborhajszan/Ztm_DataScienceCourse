{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-Learn (sklearn) Course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:navajowhite\">\n",
    "--- topics covered<br>\n",
    "0. sklearn workflow overview<br>\n",
    "1. preparing data (collecting, features/targets, splitting)<br>\n",
    "2. defining problem / selecting machine learning estimator/algorithm/model<br>\n",
    "3. training model and making predictions<br>\n",
    "4. evaluating model<br>\n",
    "5. improving model<br>\n",
    "6. saving and loading model<br>\n",
    "7. putting it all together\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### imports\n",
    "import pickle\n",
    "import numpy, pandas\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "### displaying matplotlib figures within notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### pandas dataframe (heart_disease), reading data from csv file\n",
    "heart_disease = pandas.read_csv(\"data-heart-disease.csv\")\n",
    "### pandas dataframe (features), contains heart_disease dataframe, dropping heart_disease/target\n",
    "features = heart_disease.drop(columns=\"target\")\n",
    "### pandas series (target), contains heart_disease/target\n",
    "target = heart_disease.loc[:, \"target\"]\n",
    "### splitting data into train/test sets\n",
    "### features >>> features_train, features_test\n",
    "### target >>> target_train, target_test\n",
    "### test set size is 20% of all data (test_size)\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.2)\n",
    "features_train: numpy.ndarray; features_test: numpy.ndarray; target_train: numpy.ndarray; target_test: numpy.ndarray\n",
    "features_train.shape, features_test.shape, target_train.shape, target_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Selecting machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### instantiating a random forest classifier\n",
    "classifier = RandomForestClassifier()\n",
    "### listing classifier parameters\n",
    "classifier.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Training model / Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### fitting classifier to training dataset\n",
    "classifier.fit(features_train, target_train)\n",
    "### making predictions with trained classifier on test dataset\n",
    "target_prediction = classifier.predict(features_test)\n",
    "### viewing classifier predictions\n",
    "target_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Evaluating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### classifier accuracy score on training dataset\n",
    "print(classifier.score(features_train, target_train))\n",
    "### classifier accuracy score on test dataset\n",
    "print(classifier.score(features_test, target_test))\n",
    "### classifier accuracy score on test dataset\n",
    "print(accuracy_score(target_test, target_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### classifier main metrics on test dataset\n",
    "print(classification_report(target_test, target_prediction))\n",
    "### classifier confusion matrix on test dataset\n",
    "print(confusion_matrix(target_test, target_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Improving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### adjusting number of estimators (n-estimators)\n",
    "for num_estimators in range(10, 100, 10):\n",
    "    print(f\"Trying classifier with {num_estimators} estimators...\")\n",
    "    classifier = RandomForestClassifier(n_estimators=num_estimators)\n",
    "    classifier.fit(features_train, target_train)\n",
    "    print(f\"Classifier accuracy score on test dataset: {classifier.score(features_test, target_test)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Saving model / Loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### saving classifier (dump) into pickle binary file\n",
    "pickle.dump(classifier, open(\"model-random-forest-1.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### loading classifier from pickle binary file\n",
    "classifier_loaded: RandomForestClassifier = pickle.load(open(\"model-random-forest-1.pkl\", \"rb\"))\n",
    "### loaded classifier accuracy score on test dataset\n",
    "classifier_loaded.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:navajowhite\">\n",
    "--- main steps<br>\n",
    "splitting data (features, targets, train, test)<br>\n",
    "handling missing values (filling or omitting)<br>\n",
    "converting non-numerical values (feature encoding)\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### pandas dataframe (heart_disease), reading data from csv file\n",
    "heart_disease = pandas.read_csv(\"data-heart-disease.csv\")\n",
    "### pandas dataframe (features), contains heart_disease dataframe, dropping heart_disease/target\n",
    "features = heart_disease.drop(columns=\"target\")\n",
    "### pandas series (target), contains heart_disease/target\n",
    "target = heart_disease.loc[:, \"target\"]\n",
    "### splitting data into train/test sets\n",
    "### features >>> features_train, features_test\n",
    "### target >>> target_train, target_test\n",
    "### test set size is 20% of all data (test_size)\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.2)\n",
    "features_train: numpy.ndarray; features_test: numpy.ndarray; target_train: numpy.ndarray; target_test: numpy.ndarray\n",
    "features_train.shape, features_test.shape, target_train.shape, target_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### imports ------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### collecting data ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "### pandas dataframe (car_sales), reading data from csv file\n",
    "car_sales = pandas.read_csv(\"data-car-sales-extended.csv\")\n",
    "\n",
    "car_sales.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### splitting data: features / target ----------------------------------------------------------------------------------\n",
    "\n",
    "### pandas dataframe (features), contains car_sales dataframe, dropping car_sales/Price\n",
    "features = car_sales.drop(columns=\"Price\")\n",
    "### pandas series (target), contains car_sales/Price\n",
    "target = car_sales.loc[:, \"Price\"]\n",
    "\n",
    "features, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### sklearn feature encoding -------------------------------------------------------------------------------------------\n",
    "\n",
    "### column transformer object (transformer), named \"one_hot\", using OneHotEncoder()\n",
    "### encodes car_sales/Make, car_sales/Colour, and car_sales/Doors, passing throung other columns (remainder)\n",
    "transformer = ColumnTransformer([(\"one_hot\", OneHotEncoder(), [\"Make\", \"Colour\", \"Doors\"])], remainder=\"passthrough\")\n",
    "### numpy array (sklearn_encoded), contains transformed features matrix\n",
    "sklearn_encoded = transformer.fit_transform(features)\n",
    "\n",
    "pandas.DataFrame(data=sklearn_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:navajowhite\">\n",
    "--- feature encoding concepts<br>\n",
    "ColumnTransformer / OneHotEncoder creates individual columns for each category<br>\n",
    "suppose a \"Planets\" column contains 4 categories: Mercury / Venus / Earth / Mars<br>\n",
    "feature encoding deletes \"Planets\" column and creates 4 new columns for each category<br>\n",
    "where \"Planets\" contained Mercury, the \"Mercury\" column gets 1, the rest get 0, etc...\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### pandas feature encoding --------------------------------------------------------------------------------------------\n",
    "\n",
    "### pandas dataframe (pandas_encoded), contains car_sales dataframe\n",
    "### encodes car_sales/Make, car_sales/Colour, and car_sales/Doors\n",
    "pandas_encoded = pandas.get_dummies(car_sales)\n",
    "\n",
    "pandas_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### splitting data: train / test ---------------------------------------------------------------------------------------\n",
    "\n",
    "### sklearn_encoded >>> features_train, features_test\n",
    "### target >>> target_train, target_test\n",
    "### test set size is 20% of all data (test_size)\n",
    "features_train, features_test, target_train, target_test = train_test_split(sklearn_encoded, target, test_size=0.2)\n",
    "\n",
    "features_train: numpy.ndarray; features_test: numpy.ndarray; target_train: numpy.ndarray; target_test: numpy.ndarray\n",
    "features_train.shape, features_test.shape, target_train.shape, target_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### training and evaluating a machine learning model -------------------------------------------------------------------\n",
    "\n",
    "### instantiating a random forest regressor (regressor)\n",
    "regressor = RandomForestRegressor()\n",
    "### fitting regressor to training dataset\n",
    "regressor.fit(features_train, target_train)\n",
    "\n",
    "### regressor accuracy scores on training and test datasets\n",
    "regressor.score(features_train, target_train), regressor.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling missing values with pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:navajowhite\">\n",
    "--- options for handling missing values<br>\n",
    "removing records containing missing value(s)<br>\n",
    "filling missing value(s) (imputation)\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### imports\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### loading dataframe\n",
    "carsales_missing = pandas.read_csv(\"data-car-sales-missing.csv\")\n",
    "carsales_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### checking for missing values\n",
    "carsales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### filling missing values\n",
    "carsales_missing[\"Make\"] = carsales_missing[\"Make\"].fillna(\"Missing\")\n",
    "carsales_missing[\"Colour\"] = carsales_missing[\"Colour\"].fillna(\"Missing\")\n",
    "carsales_missing[\"Odometer (KM)\"] = carsales_missing[\"Odometer (KM)\"].fillna(carsales_missing[\"Odometer (KM)\"].mean())\n",
    "carsales_missing[\"Doors\"] = carsales_missing[\"Doors\"].fillna(4)\n",
    "carsales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### removing rows (axis=\"index\") with missing values\n",
    "carsales_missing = carsales_missing.dropna(axis=\"index\")\n",
    "carsales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### resetting index, dropping old index column (drop=True)\n",
    "carsales_missing = carsales_missing.reset_index(drop=True)\n",
    "carsales_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling missing values with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### imports\n",
    "import pandas\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### loading dataframe\n",
    "carsales_missing = pandas.read_csv(\"data-car-sales-missing.csv\")\n",
    "carsales_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### checking for missing values\n",
    "carsales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### removing rows (axis=\"index\") with missing price value (subset=[\"Price\"])\n",
    "carsales_missing = carsales_missing.dropna(axis=\"index\", subset=[\"Price\"]).reset_index(drop=True)\n",
    "carsales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### instantiating imputers\n",
    "### constant strategy fills with fill_value\n",
    "### most_frequent strategy fills with most frequent value in column\n",
    "### mean strategy fills with mean of column\n",
    "category_imputer = SimpleImputer(strategy=\"constant\", fill_value=\"Missing\")\n",
    "door_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "numeric_imputer = SimpleImputer(strategy=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### instantiating column transformer, unspecified columns remain unchanged (remainder=\"passthrough\")\n",
    "transformer = ColumnTransformer([\n",
    "    (\"category_imputer\", category_imputer, [\"Make\", \"Colour\"]),\n",
    "    (\"door_imputer\", door_imputer, [\"Doors\"]),\n",
    "    (\"numeric_imputer\", numeric_imputer, [\"Odometer (KM)\"])],\n",
    "    remainder=\"passthrough\")\n",
    "### fitting transformers and transforming columns, returns numpy array\n",
    "carsales_filled = transformer.fit_transform(carsales_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### converting numpy array > pandas dataframe, re-checking for missing values\n",
    "carsales_filled = pandas.DataFrame(data=carsales_filled, columns=carsales_missing.columns.values)\n",
    "carsales_filled.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Selecting Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### imports\n",
    "import numpy, pandas\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### loading california housing dataset (regression problem)\n",
    "housing_dict = fetch_california_housing()\n",
    "### creating features dataframe\n",
    "housing_df = pandas.DataFrame(data=housing_dict[\"data\"], columns=housing_dict[\"feature_names\"])\n",
    "### adding target column\n",
    "housing_df[\"MedHouseVal\"] = housing_dict[\"target\"]\n",
    "housing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### splitting data features/target\n",
    "features = housing_df.drop(columns=\"MedHouseVal\")\n",
    "target = housing_df.loc[:, \"MedHouseVal\"]\n",
    "### splitting data train/test\n",
    "numpy.random.seed(42)\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:navajowhite\">\n",
    "--- model selection<br>\n",
    "model is selected from the sklean model selection map<br>\n",
    "when the map suggests several models, each one should be tested\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### instantiating, training, and evaluating a model\n",
    "regressor = Ridge()\n",
    "regressor.fit(features_train, target_train)\n",
    "regressor.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:navajowhite\">\n",
    "--- model evaluation<br>\n",
    "the score of a ridge regressor is the coefficient of determination (r-square)<br>\n",
    "r-square quantifies the linear relationship between feature and target variables\n",
    "</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('Ztm_Code': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d135630f3aba14e844087208813e69ab65195afd4ab5238b4ebe56330592421"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
