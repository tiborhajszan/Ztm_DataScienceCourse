{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Heart Disease Using Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Approach**\n",
    "1. Problem Definition\n",
    "2. Goal Definition\n",
    "3. Dataset\n",
    "4. Data Features\n",
    "5. Modeling\n",
    "6. Experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Problem Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We attempt to create a machine learning model that predicts the absence / presence of coronary heart disease.  \n",
    "Model predictions will be based on related medical records of patients.  \n",
    "The type of this machine learning problem is **supervised learning / binary classification**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Goal Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to achieve 95% accuracy with this proof of concept model to pursue the project further.  \n",
    "We need very high accuracy, because the health of patients is at stake."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we use is the Cleveland Heart Disease Dataset, which is publicly available:  \n",
    "[UCI Machine Learning Repository](https://archive.ics.uci.edu/dataset/45/heart+disease)  \n",
    "[Kaggle](https://www.kaggle.com/datasets/redwankarimsony/heart-disease-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Dictionary (information about each data feature)**\n",
    "* age (age of patient in years)\n",
    "* sex (gender of patient)  \n",
    "0 = female  \n",
    "1 = male\n",
    "* cp (chest pain type)  \n",
    "1 = typical angina (typical angina symptoms - sign of coronary heart disease)  \n",
    "2 = atypical angina (pain related to coronary heart disease, which mimics other chest pain type - usually in women)  \n",
    "3 = non-anginal (chest pain not related to coronary heart disease, like indigestion)  \n",
    "4 = asymptomatic (no chest pain)\n",
    "* trestbps (resting blood pressure in mmHg on admission to hospital)  \n",
    "High blood pressure is a risk factor of coronary heart disease.\n",
    "* chol (serum cholesterol in mg/dl)  \n",
    "High serum cholesterol is a risk factor of coronary heart disease.\n",
    "* fbs (fasting blood sugar > 120 mg/dl)  \n",
    "0 = no (no risk of coronary heart disease)  \n",
    "1 = yes (high blood sugar is a risk factor of coronary heart disease)\n",
    "* restecg (resting ECG results)  \n",
    "0 = normal ECG (sign of a healthy heart)  \n",
    "1 = ST/T wave abnormality (sign of coronary heart disease)  \n",
    "2 = left ventricular hypertrophy (sign of cardiac overload, like high blood pressure)\n",
    "* thalach (maximum heart rate achieved during thallium stress test)  \n",
    "Lower maximum heart rate is indicative of heart disease.\n",
    "* exang (exercise induced angina)  \n",
    "0 = no (sign of a healthy heart)  \n",
    "1 = yes (sign of coronary heart disease)\n",
    "* oldpeak (exercise induced ECG ST segment depression relative to resting state)  \n",
    "ECG ST segment depression may be a sign of coronary heart disease.\n",
    "* slope (slope of peak exercise induced ECG ST segment depression)  \n",
    "1 = upsloping (sign of a healthy heart)  \n",
    "2 = flat (strong sign of coronary heart disease)  \n",
    "3 = downsloping (sign of coronary heart disease)\n",
    "* ca (number of major vessels [0-3] colored by fluoroscopy)  \n",
    "Coronary heart disease reduces the number of visible vessels in fluoroscopy.\n",
    "* thal (thallium stress test result)  \n",
    "1-3 = normal (signs of a healthy heart)  \n",
    "6 = fixed defect (hypoperfusion during both resting and exercise - sign of an old myocardial infarction)  \n",
    "7 = reversible defect (hypoperfusion during only exercise - sign of coronary heart disease)\n",
    "* target (predicted variable)  \n",
    "0 = absence of heart disease (<50% narrowing of coronary arteries)  \n",
    "1 = presence of heart disease (>50% narrowing of coronary arteries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ECG - electrocardiogram**\n",
    "\n",
    "Diagnostic method that examines the electrical activity of heart muscle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**thal - Thallium Stress Test**\n",
    "\n",
    "Diagnostic method that examines the blood perfusion of heart muscle during both resting and exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the tools (Python libraries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use several Python libraries for data science and machine learning.  \n",
    "Python libraries Numpy, Pandas, Matplotlib, and Seaborn are used for data analysis and manipulation.  \n",
    "Python library Scikit-Learn (SkLearn) is used for machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### importing exploratory data analysis (EDA) tools\n",
    "import numpy\n",
    "from pandas import DataFrame, read_csv\n",
    "from matplotlib import pyplot\n",
    "import seaborn\n",
    "\n",
    "### rendering plots inside this notebook\n",
    "%matplotlib inline\n",
    "\n",
    "### importing sklearn model selection tools\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "### importing sklearn machine learning algorithms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "### importing sklearn model evaluation tools\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import RocCurveDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### importing heart disease dataset from csv file\n",
    "heart_disease: DataFrame = read_csv(filepath_or_buffer=\"data-heart-disease.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verifying dataframe integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### displaying the first 5 rows of dataframe\n",
    "heart_disease.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### displaying the last 5 rows of dataframe\n",
    "heart_disease.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### displaying dataframe dimensions\n",
    "heart_disease.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### displaying basic information of dataframe\n",
    "heart_disease.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### displaying basic statistics of numeric dataframe columns\n",
    "heart_disease.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### checking for missing values\n",
    "heart_disease.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis = EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to become a subject matter expert on the dataset.  \n",
    "1. Data basics: data types, numeric/categorical, statistics, balanced/imbalanced, etc...\n",
    "2. Cleaning data: handling missing values and outliers\n",
    "3. Transforming data: common units, standardization, encoding, etc...\n",
    "4. Data engineering: creating new features from existing ones\n",
    "5. Reducing data: removing non-relevant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### counting category instances of the target variable\n",
    "heart_disease[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### visualizing category instances of the target variable\n",
    "heart_disease[\"target\"].value_counts().plot(kind=\"bar\", color=[\"salmon\", \"lightblue\"])\n",
    "pyplot.title(label=\"Category Instances of Target Variable\")\n",
    "pyplot.ylabel(ylabel=\"Counts\")\n",
    "pyplot.xlabel(xlabel=\"Target Variable (Heart Disease): 0=No 1=Yes\")\n",
    "pyplot.xticks(rotation=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### checking for missing values\n",
    "heart_disease.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sex of patient and heart disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### counting category instances of sex variable :)\n",
    "### sex: 0=female, 1=male\n",
    "heart_disease[\"sex\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### comparing sex column to target column with cross tabulation\n",
    "### sex: 0=female, 1=male\n",
    "### target: 0=no disease, 1=disease\n",
    "pandas.crosstab(index=heart_disease[\"sex\"], columns=heart_disease[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plotting heart disease frequency over sex of patient\n",
    "pandas.crosstab(index=heart_disease[\"sex\"], columns=heart_disease[\"target\"]).plot(\n",
    "    kind=\"bar\", color=[\"lightblue\", \"salmon\"])\n",
    "pyplot.title(label=\"Heart Disease Frequency by Sex\")\n",
    "pyplot.ylabel(ylabel=\"Patient Count\")\n",
    "pyplot.xlabel(xlabel=\"Sex of Patient\")\n",
    "pyplot.legend([\"No Heart Disease\", \"Heart Disease\"])\n",
    "pyplot.xticks(ticks=[0,1], labels=[\"Female\", \"Male\"], rotation=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maximum Heart Rate vs. Age and Heart Disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### histogram: distribution of maximum heart rate values\n",
    "heart_disease[\"thalach\"].plot.hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### histogram: distribution of age values\n",
    "heart_disease[\"age\"].plot.hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### creating figure object\n",
    "pyplot.figure(figsize=(10,6))\n",
    "\n",
    "### scatter plot: maximum heart rate over age in no heart disease\n",
    "pyplot.scatter(\n",
    "    y=heart_disease[\"thalach\"][heart_disease[\"target\"]==0],\n",
    "    x=heart_disease[\"age\"][heart_disease[\"target\"]==0],\n",
    "    color=\"lightblue\")\n",
    "\n",
    "### scatter plot: maximum heart rate over age in heart disease\n",
    "pyplot.scatter(\n",
    "    y=heart_disease[\"thalach\"][heart_disease[\"target\"]==1],\n",
    "    x=heart_disease[\"age\"][heart_disease[\"target\"]==1],\n",
    "    color=\"salmon\")\n",
    "\n",
    "### configuring scatter plots\n",
    "pyplot.title(label=\"Maximum Heart Rate vs. Age and Heart Disease\")\n",
    "pyplot.legend([\"No Heart Disease\", \"Heart Disease\"]);\n",
    "pyplot.ylabel(ylabel=\"Maximum Heart Rate\")\n",
    "pyplot.xlabel(xlabel=\"Age of Patient\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chest pain type and heart disease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*cp (chest pain type)*\n",
    "* 1 = typical angina (chest pain related to impaired blood supply of heart)\n",
    "* 2 = atypical angina (chest pain not related to impaired blood supply of heart)\n",
    "* 3 = non-anginal (typically easophageal spasm)\n",
    "* 4 = asymptomatic (chest pain not related to heart disease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### crosstab: chest pain type vs heart disease\n",
    "pandas.crosstab(index=heart_disease[\"cp\"], columns=heart_disease[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### bar graph: heart disease frequency over chest pain type\n",
    "pandas.crosstab(index=heart_disease[\"cp\"], columns=heart_disease[\"target\"]).plot(\n",
    "    kind=\"bar\", color=[\"lightblue\", \"salmon\"])\n",
    "\n",
    "### configuring bar graph\n",
    "pyplot.title(label=\"Heart Disease Frequency Over Chest Pain Type\")\n",
    "pyplot.legend([\"No Heart Disease\", \"Heart Disease\"])\n",
    "pyplot.ylabel(ylabel=\"Patient Count\")\n",
    "pyplot.xlabel(xlabel=\"Chest Pain Type\")\n",
    "pyplot.xticks(ticks=[0,1,2,3], labels=[\"Typical Angina\", \"Atypical Angina\", \"Non-Anginal\", \"Asymptomatic\"], rotation=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### creating correlation matrix with pandas\n",
    "correlation_matrix = heart_disease.corr()\n",
    "correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### visualizing correlation matrix with seaborn\n",
    "figure, axis = pyplot.subplots(figsize=(14,10))\n",
    "axis = seaborn.heatmap(data=correlation_matrix, linewidths=1.0, cmap=\"YlGnBu\", annot=True, fmt=\".2f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting data into training and test sets.  \n",
    "The machine learning algorithm is trained (finds patterns) on the training set.  \n",
    "The trained algorithm is then tested (applies patterns) on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### splitting data features <> target\n",
    "features = heart_disease.drop(columns=\"target\")\n",
    "target = heart_disease.loc[:, \"target\"]\n",
    "\n",
    "### splitting data train <> test\n",
    "numpy.random.seed(seed=42)\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting machine learning algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Three machine learning algorithms will be applied and compared**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Logistic Regression\n",
    "2. K-Nearest Neighbours Classifier\n",
    "3. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These algorithms were selected from to the sklearn model selection map.  \n",
    "[Sklearn Model Selection Map](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### creating algorithm dictionary\n",
    "algo_dict = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"K-Nearest Neighbours Classifier\": KNeighborsClassifier(),\n",
    "    \"Random Forest Classifier\": RandomForestClassifier()}\n",
    "\n",
    "### creating scores dictionary\n",
    "score_dict = {}\n",
    "\n",
    "### training and evaluating algorithms\n",
    "numpy.random.seed(seed=42)\n",
    "for name, algo in algo_dict.items():\n",
    "    algo.fit(features_train, target_train)\n",
    "    score_dict[name] = algo.score(features_test, target_test)\n",
    "\n",
    "### displaying scores\n",
    "score_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### visualizing algorithm performance\n",
    "score_df = pandas.DataFrame(data=score_dict, index=[\"Accuracy\"])\n",
    "score_df.T.plot(kind=\"bar\", figsize=(8,6), legend=None)\n",
    "pyplot.title(label=\"Algorithm Performance on the Heart Disease Dataset\", fontsize=14)\n",
    "pyplot.ylabel(ylabel=\"Accuracy\", fontsize=14)\n",
    "pyplot.xticks(rotation=0)\n",
    "pyplot.xlabel(xlabel=\"Machine Learning Algorithm\", fontsize=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model improvement / Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a baseline model that we try to improve using:\n",
    "* hyperparameter tuning\n",
    "* feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tools for evaluating the performance of a classification algorithm:\n",
    "* confusion matrix\n",
    "* classification report\n",
    "* accuracy / precision / recall / f1-score\n",
    "* cross-validation\n",
    "* ROC curve / area under the ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### nearest neighbors classifier hyperparameter tuning by hand\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "for k_neighbors in range(1,21):\n",
    "    knn_classifier.set_params(n_neighbors=k_neighbors)\n",
    "    knn_classifier.fit(X=features_train, y=target_train)\n",
    "    train_scores.append(knn_classifier.score(X=features_train, y=target_train))\n",
    "    test_scores.append(knn_classifier.score(X=features_test, y=target_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plotting nearest neighbors classifier tuning scores\n",
    "pyplot.plot(range(1,21), train_scores, label=\"Training Scores\")\n",
    "pyplot.plot(range(1,21), test_scores, label=\"Test Scores\")\n",
    "pyplot.title(label=\"Nearest Neighbors Classifier Hyperparameter Tuning\")\n",
    "pyplot.ylabel(ylabel=\"Accurarcy\")\n",
    "max_score = max(test_scores)\n",
    "pyplot.axhline(y=max_score, color=\"black\", linestyle=\"dotted\", label=f\"Best Score = {max_score:.3f}\")\n",
    "pyplot.xlabel(xlabel=\"Number of Neighbors\")\n",
    "pyplot.xticks(ticks=range(1,21,2))\n",
    "best_param = test_scores.index(max(test_scores)) + 1\n",
    "pyplot.axvline(x=best_param, color=\"black\", linestyle=\"dashed\", label=f\"Best Param = {best_param}\")\n",
    "pyplot.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning using Randomized Search Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance of the K Nearest Neighbors Classifier algorithm is too weak - no further use...  \n",
    "We continue by searching for better hyperparameters of Logistic Regression and Random Forest Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### logistic regression: creating hyperparameter grid\n",
    "logreg_grid = {\n",
    "    \"C\": numpy.logspace(start=-4, stop=4, num=20),\n",
    "    \"solver\": [\"liblinear\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### logistic regression: randomized search for best parameters\n",
    "numpy.random.seed(seed=42)\n",
    "logreg_random = RandomizedSearchCV(\n",
    "    estimator=LogisticRegression(), param_distributions=logreg_grid, cv=5, n_iter=20, verbose=True)\n",
    "logreg_random.fit(X=features, y=target)\n",
    "logreg_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### logistic regression: scoring best model\n",
    "logreg_random.score(X=features_test, y=target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### random forest classifier: creating hyperparameter grid\n",
    "forest_grid = {\n",
    "    \"n_estimators\": range(10, 1000, 50),\n",
    "    \"max_depth\": [None, 3, 5, 10],\n",
    "    \"min_samples_split\": range(2, 20, 2),\n",
    "    \"min_samples_leaf\": range(1, 20, 2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### random forest classifier: randomized search for best parameters\n",
    "numpy.random.seed(seed=42)\n",
    "forest_random = RandomizedSearchCV(\n",
    "    estimator=RandomForestClassifier(), param_distributions=forest_grid, cv=5, n_iter=20, verbose=True)\n",
    "forest_random.fit(X=features, y=target)\n",
    "forest_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### random forest classifier: scoring best model\n",
    "forest_random.score(X=features_test, y=target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning using Grid Search Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After randomized hyperparameter search, the Logistic Regression algorithm provides the best performance.  \n",
    "We continue by tuning the Logistic Regression algorithm even further (if possible).  \n",
    "We use Grid Search Cross Validation that performs an exhaustive hyperparameter search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### logistic regression: creating hyperparameter dictionary\n",
    "logreg_params = {\n",
    "    \"C\": numpy.logspace(start=-4, stop=4, num=30),\n",
    "    \"solver\": [\"liblinear\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### logistic regression: grid search for best parameters\n",
    "logreg_grid = GridSearchCV(estimator=LogisticRegression(), param_grid=logreg_params, cv=5, verbose=True)\n",
    "logreg_grid.fit(X=features, y=target)\n",
    "logreg_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### logistic regression: scoring best model\n",
    "logreg_grid.score(X=features_test, y=target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The following metrics will be computed:**\n",
    "* Confusion Matrix\n",
    "* Classification Report\n",
    "* Precision\n",
    "* Recall\n",
    "* F1 Score\n",
    "* ROC Curve and AUC Score\n",
    "\n",
    "Cross validation will be applied where possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### making predictions with best model\n",
    "target_preds = logreg_grid.predict(X=features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plotting roc curve of best model\n",
    "RocCurveDisplay.from_estimator(estimator=logreg_grid, X=features_test, y=target_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plotting confusion matrix using seaborn heatmap\n",
    "seaborn.set(font_scale=1.5)\n",
    "figure, axis = pyplot.subplots(figsize=(3,3))\n",
    "axis = seaborn.heatmap(data=confusion_matrix(y_true=target_test, y_pred=target_preds), annot=True, cbar=False)\n",
    "axis.set_ylabel(ylabel=\"Target Labels\")\n",
    "axis.xaxis.set_ticks_position(position=\"top\")\n",
    "axis.tick_params(axis=\"x\", which=\"both\", top=False)\n",
    "axis.xaxis.set_label_position(position=\"top\")\n",
    "axis.set_xlabel(xlabel=\"Predicted Labels\", labelpad=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### obtaining classification report\n",
    "print(classification_report(y_true=target_test, y_pred=target_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### calculating cross validated accuracy\n",
    "accuracy_cv = cross_val_score(\n",
    "    estimator=logreg_grid.best_estimator_, X=features, y=target, cv=5, scoring=\"accuracy\").mean()\n",
    "accuracy_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### calculating cross validated precision\n",
    "precision_cv = cross_val_score(\n",
    "    estimator=logreg_grid.best_estimator_, X=features, y=target, cv=5, scoring=\"precision\").mean()\n",
    "precision_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### calculating cross validated recall\n",
    "recall_cv = cross_val_score(estimator=logreg_grid.best_estimator_, X=features, y=target, cv=5, scoring=\"recall\").mean()\n",
    "recall_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### calculating cross validated f1 score\n",
    "f1_cv = cross_val_score(estimator=logreg_grid.best_estimator_, X=features, y=target, cv=5, scoring=\"f1\").mean()\n",
    "f1_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### visualizing cross validated metrics\n",
    "metrics_df = pandas.DataFrame(\n",
    "    data=[accuracy_cv,precision_cv,recall_cv,f1_cv],\n",
    "    columns=[\"Score\"],\n",
    "    index=[\"Accuracy\",\"Precision\",\"Recall\",\"F1 Score\"])\n",
    "metrics_df.plot(kind=\"bar\", legend=False)\n",
    "pyplot.title(label=\"Cross-Validated Classification Metrics\", fontsize=16)\n",
    "pyplot.yticks(fontsize=12)\n",
    "pyplot.ylabel(ylabel=\"Score\", fontsize=16)\n",
    "pyplot.xticks(fontsize=12, rotation=0)\n",
    "pyplot.xlabel(xlabel=\"Metrics\", fontsize=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much did each feature contribute to model outcome?  \n",
    "Finding feature importance is different for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### displaying feature coefficients\n",
    "logreg_grid.best_estimator_.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### mapping coefficients to feature names (columns)\n",
    "coeff_map = dict(zip(heart_disease.columns, tuple(logreg_grid.best_estimator_.coef_[0])))\n",
    "coeff_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### visualizing coefficients\n",
    "coeff_df = pandas.DataFrame(data=coeff_map.values(), index=coeff_map.keys(), columns=[\"Coefficient\"])\n",
    "coeff_df.plot(kind=\"bar\", legend=False)\n",
    "pyplot.title(label=\"Feature Importance\", fontsize=16)\n",
    "pyplot.ylabel(ylabel=\"Coefficient\", fontsize=16)\n",
    "pyplot.yticks(fontsize=12)\n",
    "pyplot.xlabel(xlabel=\"Feature\", fontsize=16);\n",
    "pyplot.xticks(fontsize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model persistence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ways to improve the model when the evaluation metric is not met:**\n",
    "* Collecting more data\n",
    "* Further tuning the current logistic regression model\n",
    "* Trying better algorithms like CatBoost or XgBoost"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
