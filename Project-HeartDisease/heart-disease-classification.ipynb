{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Heart Disease Using Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Project Framework**\n",
    "1. Problem Definition\n",
    "2. Goal Definition\n",
    "3. Dataset\n",
    "4. Data Features\n",
    "5. Modeling\n",
    "6. Experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Problem Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We attempt to create a machine learning model that predicts the absence / presence of coronary heart disease.  \n",
    "Model predictions are based on related medical records of patients.  \n",
    "The type of this machine learning problem is **supervised learning / binary classification**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Goal Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coronary arteries are the main blood vessels of the heart, providing blood supply to heart muscle.  \n",
    "Narrowing of coronary arteries results in coronary heart disease due to reduced blood supply of heart muscle.  \n",
    "Usually, the first symptom of coronary heart disease is chest pain (angina) during exercise.  \n",
    "Severe coronary heart disease causes angina during resting, and may lead to myocardial infarction.\n",
    "\n",
    "Because of the potentially severe health consequences, we need very high accuracy from the machine learning model.  \n",
    "As a result, our goal is to achieve 95% accuracy during the proof of concept phase to pursue the project further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we use is the Cleveland Heart Disease Dataset, which is publicly available:  \n",
    "[UCI Machine Learning Repository](https://archive.ics.uci.edu/dataset/45/heart+disease)  \n",
    "[Kaggle](https://www.kaggle.com/datasets/redwankarimsony/heart-disease-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Dictionary**  \n",
    "(information about each data feature)\n",
    "* age (age of patient in years)\n",
    "* sex (gender of patient)  \n",
    "0 = female  \n",
    "1 = male\n",
    "* cp (chest pain type)  \n",
    "1 = typical angina (typical angina symptoms - sign of coronary heart disease)  \n",
    "2 = atypical angina (pain related to coronary heart disease, which mimics other chest pain type - usually in women)  \n",
    "3 = non-anginal (chest pain not related to coronary heart disease, like indigestion)  \n",
    "4 = asymptomatic (no chest pain)\n",
    "* trestbps (resting blood pressure in mmHg on admission to hospital)  \n",
    "High blood pressure is a risk factor of coronary heart disease.\n",
    "* chol (serum cholesterol in mg/dl)  \n",
    "High serum cholesterol is a risk factor of coronary heart disease.\n",
    "* fbs (fasting blood sugar > 120 mg/dl)  \n",
    "0 = no (no risk of coronary heart disease)  \n",
    "1 = yes (high blood sugar is a risk factor of coronary heart disease)\n",
    "* restecg (resting ECG results)  \n",
    "0 = normal ECG (sign of a healthy heart)  \n",
    "1 = ST/T wave abnormality (sign of coronary heart disease)  \n",
    "2 = left ventricular hypertrophy (sign of cardiac overload, like high blood pressure)\n",
    "* thalach (maximum heart rate achieved during thallium stress test)  \n",
    "Lower maximum heart rate is indicative of heart disease.\n",
    "* exang (exercise induced angina)  \n",
    "0 = no (sign of a healthy heart)  \n",
    "1 = yes (sign of coronary heart disease)\n",
    "* oldpeak (exercise induced ECG ST segment depression relative to its resting state)  \n",
    "ECG ST segment depression may be a sign of coronary heart disease.\n",
    "* slope (slope of peak exercise induced ECG ST segment depression)  \n",
    "1 = upsloping (sign of a healthy heart)  \n",
    "2 = flat (strong sign of coronary heart disease)  \n",
    "3 = downsloping (sign of coronary heart disease)\n",
    "* ca (number of major vessels [0-3] colored by fluoroscopy)  \n",
    "Coronary heart disease reduces the number of visible vessels in fluoroscopy.\n",
    "* thal (thallium stress test result)  \n",
    "1-3 = normal (signs of a healthy heart)  \n",
    "6 = fixed defect (hypoperfusion during both resting and exercise - sign of an old myocardial infarction)  \n",
    "7 = reversible defect (hypoperfusion during only exercise - sign of coronary heart disease)\n",
    "* target (predicted variable)  \n",
    "0 = healthy, i.e., absence of coronary heart disease (<50% narrowing of coronary arteries)  \n",
    "1 = diseased, i.e., presence of coronary heart disease (>50% narrowing of coronary arteries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ECG - electrocardiogram**\n",
    "\n",
    "Diagnostic method that examines the electrical activity of heart muscle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**thal - thallium stress test**\n",
    "\n",
    "Diagnostic method that examines blood perfusion of heart muscle during both resting and exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the tools (Python libraries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Python libraries used in this project**\n",
    "\n",
    "We use several Python libraries for data science and machine learning.  \n",
    "Python libraries Numpy, Pandas, Matplotlib, and Seaborn are used for data analysis and manipulation.  \n",
    "Python library Scikit-Learn (Sklearn) is used for machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### importing python standard libraries\n",
    "from typing import List\n",
    "\n",
    "### importing exploratory data analysis (EDA) tools\n",
    "import numpy\n",
    "from pandas import read_csv, Series, DataFrame, crosstab\n",
    "from matplotlib import pyplot\n",
    "import seaborn\n",
    "\n",
    "### rendering plots inside this notebook\n",
    "%matplotlib inline\n",
    "\n",
    "### importing sklearn model selection tools\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "### importing sklearn machine learning algorithms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "### importing sklearn model evaluation tools\n",
    "from sklearn.metrics import confusion_matrix, classification_report, RocCurveDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### importing heart disease dataset from csv file\n",
    "heart_disease: DataFrame = read_csv(filepath_or_buffer=\"data-heart-disease.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verifying dataframe integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### displaying the first 5 rows of dataframe\n",
    "heart_disease.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### displaying the last 5 rows of dataframe\n",
    "heart_disease.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### displaying basic information of dataframe\n",
    "heart_disease.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### displaying basic statistics of numeric dataframe columns\n",
    "heart_disease.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### checking for missing values\n",
    "heart_disease.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation:**  \n",
    "The heart disease dataframe contains 303 samples (patient records).  \n",
    "There are 13 feature (independent variable) columns and a single target (dependent variable) column.  \n",
    "All columns contain numeric values.  \n",
    "There are no missing values in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploratory data analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to become a subject matter expert on the dataset.  \n",
    "* Verifying data integrity: missing values and outliers.\n",
    "* Transforming data: common units, normalization, standardization, encoding, etc...\n",
    "* Data engineering: creating new features and/or removing non-relevant features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring the target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**target (predicted variable)**\n",
    "\n",
    "0 = healthy, i.e., absence of coronary heart disease (<50% narrowing of coronary arteries)  \n",
    "1 = diseased, i.e., presence of coronary heart disease (>50% narrowing of coronary arteries)\n",
    "\n",
    "The `target` column contains numeric categorical values of integer type.  \n",
    "There are no missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plotting the distribution of target variable\n",
    "heart_disease[\"target\"].value_counts().sort_index().plot(\n",
    "    kind=\"bar\",\n",
    "    color=[\"lightblue\", \"salmon\"])\n",
    "y_values: List[int] = heart_disease[\"target\"].value_counts().sort_index().values.tolist()\n",
    "pyplot.text(\n",
    "    x=0.0,\n",
    "    y=y_values[0]/2,\n",
    "    s=y_values[0],\n",
    "    ha=\"center\")\n",
    "pyplot.text(\n",
    "    x=1.0,\n",
    "    y=y_values[1]/2,\n",
    "    s=y_values[1],\n",
    "    ha=\"center\")\n",
    "\n",
    "### customizing plot\n",
    "pyplot.title(label=\"Distribution of Target Variable\")\n",
    "pyplot.ylabel(ylabel=\"Patient Count\")\n",
    "pyplot.xlabel(xlabel=\"Target Value\")\n",
    "pyplot.xticks(\n",
    "    ticks=[0,1],\n",
    "    labels=[\"0 = Healthy\", \"1 = Diseased\"],\n",
    "    rotation=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation:**  \n",
    "There are no outliers.  \n",
    "The distribution of target variable is balanced (approximately equal number of patients in each class)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring feature: Age of patient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `age` column contains numeric continuous values of integer type.  \n",
    "There are no missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plotting the age distribution of patients\n",
    "heart_disease[\"age\"].hist(\n",
    "    color=\"steelblue\",\n",
    "    grid=False)\n",
    "pyplot.vlines(\n",
    "    x=heart_disease[\"age\"].mean(),\n",
    "    ymin=pyplot.ylim()[0],\n",
    "    ymax=pyplot.ylim()[1],\n",
    "    colors=\"orange\",\n",
    "    linewidth=4.0,\n",
    "    label=f\"\"\"Mean = {heart_disease[\"age\"].mean():.1f}\"\"\")\n",
    "pyplot.legend()\n",
    "\n",
    "### customizing plot\n",
    "pyplot.title(label=\"Age Distribution of Patients\")\n",
    "pyplot.ylabel(ylabel=\"Patient Count\")\n",
    "pyplot.xlabel(xlabel=\"Patient Age in Years\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation:**  \n",
    "There are no outliers.  \n",
    "The age distribution does not appear to be normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### calculating age distribution statistics\n",
    "print(\"Distribution Statistics\")\n",
    "print(\"mean:\\t\\t\", heart_disease[\"age\"].mean())\n",
    "print(\"kurtosis:\\t\", heart_disease[\"age\"].kurt())\n",
    "print(\"skewness:\\t\", heart_disease[\"age\"].skew())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation:**  \n",
    "The age distribution is quite platykurtic (thin-tailed), i.e., it is closer to the uniform distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### grouping age by target\n",
    "healthy_age: Series = heart_disease.loc[heart_disease[\"target\"] == 0, \"age\"]\n",
    "diseased_age: Series = heart_disease.loc[heart_disease[\"target\"] == 1, \"age\"]\n",
    "\n",
    "### calculating distribution bin boundaries\n",
    "age_range: int = heart_disease[\"age\"].max() - heart_disease[\"age\"].min()\n",
    "age_bins: List[float] = [heart_disease[\"age\"].min()+value*age_range/10 for value in range(11)]\n",
    "\n",
    "### plotting age distributions of healthy and diseased\n",
    "healthy_age.hist(\n",
    "    grid=False,\n",
    "    bins=age_bins,\n",
    "    color=\"lightblue\",\n",
    "    label=\"Distribution (Healthy)\")\n",
    "diseased_age.hist(\n",
    "    grid=False,\n",
    "    bins=age_bins,\n",
    "    color=\"salmon\",\n",
    "    alpha=0.5,\n",
    "    label=\"Distribution (Diseased)\")\n",
    "bottom,top = pyplot.ylim()\n",
    "pyplot.vlines(\n",
    "    x=healthy_age.mean(),\n",
    "    ymin=bottom,\n",
    "    ymax=top,\n",
    "    colors=\"steelblue\",\n",
    "    linewidth=3.0,\n",
    "    label=f\"Mean (Healthy) = {healthy_age.mean():.1f}\")\n",
    "pyplot.vlines(\n",
    "    x=diseased_age.mean(),\n",
    "    ymin=bottom,\n",
    "    ymax=top,\n",
    "    colors=\"orangered\",\n",
    "    linewidth=3.0,\n",
    "    label=f\"Mean (Diseased) = {diseased_age.mean():.1f}\")\n",
    "pyplot.legend()\n",
    "\n",
    "### customizing plot\n",
    "pyplot.title(label=\"Coronary Heart Disease by Patient Age\")\n",
    "pyplot.ylabel(ylabel=\"Patient Count\")\n",
    "pyplot.xlabel(xlabel=\"Patient Age in Years\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation:**  \n",
    "There are more diseased patients in younger groups and more healthy patient in older groups.  \n",
    "It does not make too much sense, and may be the result of sampling error.  \n",
    "The age distribution of healthy patients appears to be normal with left skew.  \n",
    "The age distribution of diseased patients is apparently not normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### calculating age distribution statistics of healthy and diseased\n",
    "print(\"Distribution Statistics (Healthy vs. Diseased)\")\n",
    "print(\"Healthy\")\n",
    "print(\"mean:\\t\\t\", healthy_age.mean())\n",
    "print(\"kurtosis:\\t\", healthy_age.kurt())\n",
    "print(\"skewness:\\t\", healthy_age.skew())\n",
    "print(\"Diseased\")\n",
    "print(\"mean:\\t\\t\", diseased_age.mean())\n",
    "print(\"kurtosis:\\t\", diseased_age.kurt())\n",
    "print(\"skewness:\\t\", diseased_age.skew())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation:**  \n",
    "Age distribution of the healthy is normal with quite a left skew, i.e., its average is closer to old groups.  \n",
    "Age distribution of the diseased is strongly platykurtic (thin-tailed), i.e., it is quite uniformly distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring feature: Gender of patient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**sex (gender of patient)**\n",
    "\n",
    "0 = female  \n",
    "1 = male\n",
    "\n",
    "The `sex` column contains numeric categorical values of integer type.  \n",
    "There are no missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plotting distribution of patient gender\n",
    "heart_disease[\"sex\"].value_counts().sort_index().plot(\n",
    "    kind=\"bar\",\n",
    "    color=\"steelblue\")\n",
    "y_values: List[int] = heart_disease[\"sex\"].value_counts().sort_index().values.tolist()\n",
    "pyplot.text(\n",
    "    x=0.0,\n",
    "    y=y_values[0]/2,\n",
    "    s=y_values[0],\n",
    "    color=\"navajowhite\",\n",
    "    ha=\"center\")\n",
    "pyplot.text(\n",
    "    x=1.0,\n",
    "    y=y_values[1]/2,\n",
    "    s=y_values[1],\n",
    "    color=\"navajowhite\",\n",
    "    ha=\"center\")\n",
    "\n",
    "### customizing the plot\n",
    "pyplot.title(label=\"Distribution of Patient Gender\")\n",
    "pyplot.ylabel(ylabel=\"Patient Count\")\n",
    "pyplot.xlabel(xlabel=\"Gender\")\n",
    "pyplot.xticks(\n",
    "    ticks=[0,1],\n",
    "    labels=[\"0 = Female\", \"1 = Male\"],\n",
    "    rotation=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation:**  \n",
    "There are no outliers.  \n",
    "In our sample, the distribution of patient gender is imbalanced (much more males than females)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### crosstabulating sex <> gender with pandas\n",
    "sex_target = crosstab(\n",
    "    index=heart_disease[\"sex\"],\n",
    "    columns=heart_disease[\"target\"])\n",
    "\n",
    "### plotting distribution of patient gender in coronary heart disease\n",
    "sex_target.plot(\n",
    "    kind=\"bar\",\n",
    "    color=[\"lightblue\", \"salmon\"])\n",
    "pyplot.legend([\"Healthy\", \"Diseased\"])\n",
    "\n",
    "### customizing the plot\n",
    "pyplot.title(label=\"Patient Gender in Coronary Heart Disease\")\n",
    "pyplot.ylabel(ylabel=\"Patient Count\")\n",
    "pyplot.xlabel(xlabel=\"Gender\")\n",
    "pyplot.xticks(\n",
    "    ticks=[0,1],\n",
    "    labels=[\"Female\", \"Male\"],\n",
    "    rotation=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation:**  \n",
    "In our sample, the presence of coronary heart disease is much higher in women than in men.  \n",
    "Consequently, the `sex` feature must be flawed in this dataset, because it contradicts clinical observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maximum Heart Rate vs. Age and Heart Disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### histogram: distribution of maximum heart rate values\n",
    "heart_disease[\"thalach\"].plot.hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### histogram: distribution of age values\n",
    "heart_disease[\"age\"].plot.hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### creating figure object\n",
    "pyplot.figure(figsize=(10,6))\n",
    "\n",
    "### scatter plot: maximum heart rate over age in no heart disease\n",
    "pyplot.scatter(\n",
    "    y=heart_disease[\"thalach\"][heart_disease[\"target\"]==0],\n",
    "    x=heart_disease[\"age\"][heart_disease[\"target\"]==0],\n",
    "    color=\"lightblue\")\n",
    "\n",
    "### scatter plot: maximum heart rate over age in heart disease\n",
    "pyplot.scatter(\n",
    "    y=heart_disease[\"thalach\"][heart_disease[\"target\"]==1],\n",
    "    x=heart_disease[\"age\"][heart_disease[\"target\"]==1],\n",
    "    color=\"salmon\")\n",
    "\n",
    "### configuring scatter plots\n",
    "pyplot.title(label=\"Maximum Heart Rate vs. Age and Heart Disease\")\n",
    "pyplot.legend([\"No Heart Disease\", \"Heart Disease\"]);\n",
    "pyplot.ylabel(ylabel=\"Maximum Heart Rate\")\n",
    "pyplot.xlabel(xlabel=\"Age of Patient\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chest pain type and heart disease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*cp (chest pain type)*\n",
    "* 1 = typical angina (chest pain related to impaired blood supply of heart)\n",
    "* 2 = atypical angina (chest pain not related to impaired blood supply of heart)\n",
    "* 3 = non-anginal (typically easophageal spasm)\n",
    "* 4 = asymptomatic (chest pain not related to heart disease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### crosstab: chest pain type vs heart disease\n",
    "pandas.crosstab(index=heart_disease[\"cp\"], columns=heart_disease[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### bar graph: heart disease frequency over chest pain type\n",
    "pandas.crosstab(index=heart_disease[\"cp\"], columns=heart_disease[\"target\"]).plot(\n",
    "    kind=\"bar\", color=[\"lightblue\", \"salmon\"])\n",
    "\n",
    "### configuring bar graph\n",
    "pyplot.title(label=\"Heart Disease Frequency Over Chest Pain Type\")\n",
    "pyplot.legend([\"No Heart Disease\", \"Heart Disease\"])\n",
    "pyplot.ylabel(ylabel=\"Patient Count\")\n",
    "pyplot.xlabel(xlabel=\"Chest Pain Type\")\n",
    "pyplot.xticks(ticks=[0,1,2,3], labels=[\"Typical Angina\", \"Atypical Angina\", \"Non-Anginal\", \"Asymptomatic\"], rotation=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### calculating correlation matrix with pandas\n",
    "correlation_matrix: DataFrame = heart_disease.corr()\n",
    "\n",
    "### plotting correlation matrix heatmap with seaborn\n",
    "figure,axis = pyplot.subplots(figsize=(14,10))\n",
    "figure: pyplot.Figure; axis: pyplot.Axes\n",
    "axis = seaborn.heatmap(\n",
    "    data=correlation_matrix,\n",
    "    linewidths=1.0,\n",
    "    cmap=\"RdYlGn_r\",\n",
    "    annot=True,\n",
    "    fmt=\".2f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting data into training and test sets.  \n",
    "The machine learning algorithm is trained (finds patterns) on the training set.  \n",
    "The trained algorithm is then tested (applies patterns) on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### splitting data features <> target\n",
    "features = heart_disease.drop(columns=\"target\")\n",
    "target = heart_disease.loc[:, \"target\"]\n",
    "\n",
    "### splitting data train <> test\n",
    "numpy.random.seed(seed=42)\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting machine learning algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Three machine learning algorithms will be applied and compared**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Logistic Regression\n",
    "2. K-Nearest Neighbours Classifier\n",
    "3. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These algorithms were selected from to the sklearn model selection map.  \n",
    "[Sklearn Model Selection Map](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### creating algorithm dictionary\n",
    "algo_dict = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"K-Nearest Neighbours Classifier\": KNeighborsClassifier(),\n",
    "    \"Random Forest Classifier\": RandomForestClassifier()}\n",
    "\n",
    "### creating scores dictionary\n",
    "score_dict = {}\n",
    "\n",
    "### training and evaluating algorithms\n",
    "numpy.random.seed(seed=42)\n",
    "for name, algo in algo_dict.items():\n",
    "    algo.fit(features_train, target_train)\n",
    "    score_dict[name] = algo.score(features_test, target_test)\n",
    "\n",
    "### displaying scores\n",
    "score_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### visualizing algorithm performance\n",
    "score_df = pandas.DataFrame(data=score_dict, index=[\"Accuracy\"])\n",
    "score_df.T.plot(kind=\"bar\", figsize=(8,6), legend=None)\n",
    "pyplot.title(label=\"Algorithm Performance on the Heart Disease Dataset\", fontsize=14)\n",
    "pyplot.ylabel(ylabel=\"Accuracy\", fontsize=14)\n",
    "pyplot.xticks(rotation=0)\n",
    "pyplot.xlabel(xlabel=\"Machine Learning Algorithm\", fontsize=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model improvement / Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a baseline model that we try to improve using:\n",
    "* hyperparameter tuning\n",
    "* feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tools for evaluating the performance of a classification algorithm:\n",
    "* confusion matrix\n",
    "* classification report\n",
    "* accuracy / precision / recall / f1-score\n",
    "* cross-validation\n",
    "* ROC curve / area under the ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### nearest neighbors classifier hyperparameter tuning by hand\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "for k_neighbors in range(1,21):\n",
    "    knn_classifier.set_params(n_neighbors=k_neighbors)\n",
    "    knn_classifier.fit(X=features_train, y=target_train)\n",
    "    train_scores.append(knn_classifier.score(X=features_train, y=target_train))\n",
    "    test_scores.append(knn_classifier.score(X=features_test, y=target_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plotting nearest neighbors classifier tuning scores\n",
    "pyplot.plot(range(1,21), train_scores, label=\"Training Scores\")\n",
    "pyplot.plot(range(1,21), test_scores, label=\"Test Scores\")\n",
    "pyplot.title(label=\"Nearest Neighbors Classifier Hyperparameter Tuning\")\n",
    "pyplot.ylabel(ylabel=\"Accurarcy\")\n",
    "max_score = max(test_scores)\n",
    "pyplot.axhline(y=max_score, color=\"black\", linestyle=\"dotted\", label=f\"Best Score = {max_score:.3f}\")\n",
    "pyplot.xlabel(xlabel=\"Number of Neighbors\")\n",
    "pyplot.xticks(ticks=range(1,21,2))\n",
    "best_param = test_scores.index(max(test_scores)) + 1\n",
    "pyplot.axvline(x=best_param, color=\"black\", linestyle=\"dashed\", label=f\"Best Param = {best_param}\")\n",
    "pyplot.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning using Randomized Search Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance of the K Nearest Neighbors Classifier algorithm is too weak - no further use...  \n",
    "We continue by searching for better hyperparameters of Logistic Regression and Random Forest Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### logistic regression: creating hyperparameter grid\n",
    "logreg_grid = {\n",
    "    \"C\": numpy.logspace(start=-4, stop=4, num=20),\n",
    "    \"solver\": [\"liblinear\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### logistic regression: randomized search for best parameters\n",
    "numpy.random.seed(seed=42)\n",
    "logreg_random = RandomizedSearchCV(\n",
    "    estimator=LogisticRegression(), param_distributions=logreg_grid, cv=5, n_iter=20, verbose=True)\n",
    "logreg_random.fit(X=features, y=target)\n",
    "logreg_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### logistic regression: scoring best model\n",
    "logreg_random.score(X=features_test, y=target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### random forest classifier: creating hyperparameter grid\n",
    "forest_grid = {\n",
    "    \"n_estimators\": range(10, 1000, 50),\n",
    "    \"max_depth\": [None, 3, 5, 10],\n",
    "    \"min_samples_split\": range(2, 20, 2),\n",
    "    \"min_samples_leaf\": range(1, 20, 2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### random forest classifier: randomized search for best parameters\n",
    "numpy.random.seed(seed=42)\n",
    "forest_random = RandomizedSearchCV(\n",
    "    estimator=RandomForestClassifier(), param_distributions=forest_grid, cv=5, n_iter=20, verbose=True)\n",
    "forest_random.fit(X=features, y=target)\n",
    "forest_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### random forest classifier: scoring best model\n",
    "forest_random.score(X=features_test, y=target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning using Grid Search Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After randomized hyperparameter search, the Logistic Regression algorithm provides the best performance.  \n",
    "We continue by tuning the Logistic Regression algorithm even further (if possible).  \n",
    "We use Grid Search Cross Validation that performs an exhaustive hyperparameter search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### logistic regression: creating hyperparameter dictionary\n",
    "logreg_params = {\n",
    "    \"C\": numpy.logspace(start=-4, stop=4, num=30),\n",
    "    \"solver\": [\"liblinear\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### logistic regression: grid search for best parameters\n",
    "logreg_grid = GridSearchCV(estimator=LogisticRegression(), param_grid=logreg_params, cv=5, verbose=True)\n",
    "logreg_grid.fit(X=features, y=target)\n",
    "logreg_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### logistic regression: scoring best model\n",
    "logreg_grid.score(X=features_test, y=target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The following metrics will be computed:**\n",
    "* Confusion Matrix\n",
    "* Classification Report\n",
    "* Precision\n",
    "* Recall\n",
    "* F1 Score\n",
    "* ROC Curve and AUC Score\n",
    "\n",
    "Cross validation will be applied where possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### making predictions with best model\n",
    "target_preds = logreg_grid.predict(X=features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plotting roc curve of best model\n",
    "RocCurveDisplay.from_estimator(estimator=logreg_grid, X=features_test, y=target_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plotting confusion matrix using seaborn heatmap\n",
    "seaborn.set(font_scale=1.5)\n",
    "figure, axis = pyplot.subplots(figsize=(3,3))\n",
    "axis = seaborn.heatmap(data=confusion_matrix(y_true=target_test, y_pred=target_preds), annot=True, cbar=False)\n",
    "axis.set_ylabel(ylabel=\"Target Labels\")\n",
    "axis.xaxis.set_ticks_position(position=\"top\")\n",
    "axis.tick_params(axis=\"x\", which=\"both\", top=False)\n",
    "axis.xaxis.set_label_position(position=\"top\")\n",
    "axis.set_xlabel(xlabel=\"Predicted Labels\", labelpad=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### obtaining classification report\n",
    "print(classification_report(y_true=target_test, y_pred=target_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### calculating cross validated accuracy\n",
    "accuracy_cv = cross_val_score(\n",
    "    estimator=logreg_grid.best_estimator_, X=features, y=target, cv=5, scoring=\"accuracy\").mean()\n",
    "accuracy_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### calculating cross validated precision\n",
    "precision_cv = cross_val_score(\n",
    "    estimator=logreg_grid.best_estimator_, X=features, y=target, cv=5, scoring=\"precision\").mean()\n",
    "precision_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### calculating cross validated recall\n",
    "recall_cv = cross_val_score(estimator=logreg_grid.best_estimator_, X=features, y=target, cv=5, scoring=\"recall\").mean()\n",
    "recall_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### calculating cross validated f1 score\n",
    "f1_cv = cross_val_score(estimator=logreg_grid.best_estimator_, X=features, y=target, cv=5, scoring=\"f1\").mean()\n",
    "f1_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### visualizing cross validated metrics\n",
    "metrics_df = pandas.DataFrame(\n",
    "    data=[accuracy_cv,precision_cv,recall_cv,f1_cv],\n",
    "    columns=[\"Score\"],\n",
    "    index=[\"Accuracy\",\"Precision\",\"Recall\",\"F1 Score\"])\n",
    "metrics_df.plot(kind=\"bar\", legend=False)\n",
    "pyplot.title(label=\"Cross-Validated Classification Metrics\", fontsize=16)\n",
    "pyplot.yticks(fontsize=12)\n",
    "pyplot.ylabel(ylabel=\"Score\", fontsize=16)\n",
    "pyplot.xticks(fontsize=12, rotation=0)\n",
    "pyplot.xlabel(xlabel=\"Metrics\", fontsize=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much did each feature contribute to model outcome?  \n",
    "Finding feature importance is different for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### displaying feature coefficients\n",
    "logreg_grid.best_estimator_.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### mapping coefficients to feature names (columns)\n",
    "coeff_map = dict(zip(heart_disease.columns, tuple(logreg_grid.best_estimator_.coef_[0])))\n",
    "coeff_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### visualizing coefficients\n",
    "coeff_df = pandas.DataFrame(data=coeff_map.values(), index=coeff_map.keys(), columns=[\"Coefficient\"])\n",
    "coeff_df.plot(kind=\"bar\", legend=False)\n",
    "pyplot.title(label=\"Feature Importance\", fontsize=16)\n",
    "pyplot.ylabel(ylabel=\"Coefficient\", fontsize=16)\n",
    "pyplot.yticks(fontsize=12)\n",
    "pyplot.xlabel(xlabel=\"Feature\", fontsize=16);\n",
    "pyplot.xticks(fontsize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model persistence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ways to improve the model when the evaluation metric is not met:**\n",
    "* Collecting more data\n",
    "* Further tuning the current logistic regression model\n",
    "* Trying better algorithms like CatBoost or XgBoost"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
